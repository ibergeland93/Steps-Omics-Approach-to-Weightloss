{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "from IPython.display import Image\n",
    "! python -m pip install pydotplus\n",
    "! pip install graphviz\n",
    "import statistics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways = pd.read_csv('KEGG_7pathways_steps.csv')\n",
    "pathways = pathways.drop(['Unnamed: 0'], axis=1)\n",
    "pathways.set_index('studyID',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs = pd.read_csv('PC_final result(use in modeling) (1).csv')\n",
    "pcs = pcs.iloc[:,:6]\n",
    "pcs.set_index('studyID',inplace = True)\n",
    "pathways_2 = pd.read_csv('KEGG_7pathways_steps.csv')\n",
    "pathways_2 = pathways_2.drop(['Unnamed: 0', 'Group', 'Age', \n",
    "       'path:hsa03040-mean',\n",
    "       'path:hsa03040-variance', 'path:hsa03050-mean',\n",
    "       'path:hsa03050-variance', 'path:hsa03060-mean',\n",
    "       'path:hsa03060-variance', 'path:hsa04130-mean',\n",
    "       'path:hsa04130-variance', 'path:hsa04141-mean',\n",
    "       'path:hsa04141-variance', 'path:hsa04662-mean',\n",
    "       'path:hsa04662-variance', 'path:hsa05220-mean',\n",
    "       'path:hsa05220-variance'], axis=1)\n",
    "pathways_2.set_index('studyID', inplace = True)\n",
    "pcs = pcs.merge(pathways_2, how = 'outer', on ='studyID')\n",
    "pcs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics = pathways.drop(['Steps','path:hsa03040-mean',\n",
    "       'path:hsa03040-variance', 'path:hsa03050-mean',\n",
    "       'path:hsa03050-variance', 'path:hsa03060-mean',\n",
    "       'path:hsa03060-variance', 'path:hsa04130-mean',\n",
    "       'path:hsa04130-variance', 'path:hsa04141-mean',\n",
    "       'path:hsa04141-variance', 'path:hsa04662-mean',\n",
    "       'path:hsa04662-variance', 'path:hsa05220-mean',\n",
    "       'path:hsa05220-variance'], axis = 1)\n",
    "demographics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = pathways.drop(['path:hsa03040-mean',\n",
    "       'path:hsa03040-variance', 'path:hsa03050-mean',\n",
    "       'path:hsa03050-variance', 'path:hsa03060-mean',\n",
    "       'path:hsa03060-variance', 'path:hsa04130-mean',\n",
    "       'path:hsa04130-variance', 'path:hsa04141-mean',\n",
    "       'path:hsa04141-variance', 'path:hsa04662-mean',\n",
    "       'path:hsa04662-variance', 'path:hsa05220-mean',\n",
    "       'path:hsa05220-variance'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid for Randomized Search CV - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 400,num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto','sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5,7,10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3,4,5]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dem = demographics[['Group', 'Age', 'Gender', 'BMI']]\n",
    "Y_dem = demographics['Weight_loss_band']                  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dem,Y_dem, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random= RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, \n",
    "                               random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 188,\n",
    " min_samples_split = 10,\n",
    " min_samples_leaf = 2,\n",
    " max_features = 'sqrt',\n",
    " max_depth = 50,\n",
    " bootstrap = True , random_state = 42)\n",
    "random_forest.fit(X_train,y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "importance = pd.Series(random_forest.feature_importances_, index=X_dem.columns)\n",
    "importance.nlargest(10).plot(kind='bar');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_state = list(range(1,300))\n",
    "#print(random_state)\n",
    "d1_train_acc = []\n",
    "d1_test_acc = []\n",
    "d1_auc_score = []\n",
    "d1_prec_score = []\n",
    "d1_recall_score = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    X_dem = demographics[['Group', 'Age', 'Gender', 'BMI']]\n",
    "    Y_dem = demographics['Weight_loss_band']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_dem,Y_dem, test_size = 0.3, random_state = i) \n",
    "    \n",
    "    random_forest= RandomForestClassifier(n_estimators = 188,\n",
    "     min_samples_split = 10,\n",
    "     min_samples_leaf = 2,\n",
    "     max_features = 'sqrt',\n",
    "     max_depth = 50,\n",
    "     bootstrap = True , random_state = 42)\n",
    "    \n",
    "    random_forest.fit(X_train,y_train)\n",
    "    y_pred = random_forest.predict(X_test) \n",
    "\n",
    "    rf_train_acc = random_forest.score(X_train, y_train)\n",
    "    rf_test_acc = accuracy_score(y_test,y_pred)\n",
    "    auc_score = roc_auc_score(y_test,y_pred)\n",
    "    prec_score = average_precision_score(y_test, y_pred)\n",
    "    rec_score = recall_score(y_test,y_pred)\n",
    "\n",
    "    d1_train_acc.append(rf_train_acc)\n",
    "    d1_test_acc.append(rf_test_acc)\n",
    "    d1_auc_score.append(auc_score)\n",
    "    d1_prec_score.append(prec_score)\n",
    "    d1_recall_score.append(rec_score)\n",
    "    \n",
    "\n",
    "print('Mean Training Accuracy:', np.mean(d1_train_acc)) \n",
    "print('Mean Test Accuracy:', np.mean(d1_test_acc))\n",
    "print('Standard Deviation',statistics.stdev(d1_test_acc))\n",
    "\n",
    "print('AUC score equals',np.mean(d1_auc_score))\n",
    "print('Standard Deviation for auc score',statistics.stdev(d1_auc_score))\n",
    "print('Average precision score:', np.mean(d1_prec_score))\n",
    "print('Average recall score', np.mean(d1_recall_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf,X_train,y_train, cv=3)\n",
    "scores               \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "\n",
    "recall = cross_val_score(rf, X_train, y_train, cv=3, scoring='recall')\n",
    "print('Recall', np.mean(recall), recall.std())\n",
    "precision = cross_val_score(rf, X_train, y_train, cv=3, scoring='precision')\n",
    "print('Precision', np.mean(precision), precision.std())\n",
    "f1 = cross_val_score(rf, X_train, y_train, cv=3, scoring='f1')\n",
    "print('F1', np.mean(f1), 'std',f1.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_st = steps[['Group', 'Age', 'Gender', 'BMI', 'Steps']]\n",
    "Y_st =steps['Weight_loss_band']                  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_st,Y_st, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random= RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, \n",
    "                               random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 104,\n",
    " min_samples_split = 10,\n",
    " min_samples_leaf = 3,\n",
    " max_features = 'auto',\n",
    " max_depth = 2,\n",
    " bootstrap =  False)\n",
    "random_forest.fit(X_train,y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "importance= pd.Series(random_forest.feature_importances_, index=X_st.columns)\n",
    "importance.nlargest(5).plot(kind='bar');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "random_state = list(range(1,300))\n",
    "\n",
    "d1_train_acc = []\n",
    "d1_test_acc = []\n",
    "d1_auc_score = []\n",
    "d1_prec_score = []\n",
    "d1_recall_score = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    X_steps = pathways[['Group', 'Age', 'Gender', 'BMI',  'Steps']]\n",
    "    Y_steps = steps['Weight_loss_band']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_steps,Y_steps, test_size = 0.2, random_state = i) \n",
    "    \n",
    "    random_forest= RandomForestClassifier(n_estimators = 104,\n",
    "     min_samples_split = 10,\n",
    "     min_samples_leaf = 3,\n",
    "     max_features = 'auto',\n",
    "     max_depth = 2,\n",
    "     bootstrap =  False)\n",
    "    \n",
    "    random_forest.fit(X_train,y_train)\n",
    "    y_pred = random_forest.predict(X_test) \n",
    "\n",
    "    rf_train_acc = random_forest.score(X_train, y_train)\n",
    "    rf_test_acc = accuracy_score(y_test,y_pred)\n",
    "    auc_score = roc_auc_score(y_test,y_pred)\n",
    "    prec_score = average_precision_score(y_test, y_pred)\n",
    "    rec_score = recall_score(y_test,y_pred)\n",
    "\n",
    "    d1_train_acc.append(rf_train_acc)\n",
    "    d1_test_acc.append(rf_test_acc)\n",
    "    d1_auc_score.append(auc_score)\n",
    "    d1_prec_score.append(prec_score)\n",
    "    d1_recall_score.append(rec_score)\n",
    "    \n",
    "\n",
    "print('Mean Training Accuracy:', np.mean(d1_train_acc)) \n",
    "print('Mean Test Accuracy:', np.mean(d1_test_acc))\n",
    "print(statistics.stdev(d1_test_acc))\n",
    "\n",
    "print('AUC score equals',np.mean(d1_auc_score))\n",
    "print('Standard Deviation for auc score',statistics.stdev(d1_auc_score))\n",
    "print('Average precision score:', np.mean(d1_prec_score))\n",
    "print('Average recall score', np.mean(d1_recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf,X_train,y_train, cv=3)\n",
    "scores               \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "y_train = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "\n",
    "recall = cross_val_score(rf, X_train, y_train, cv=3, scoring='recall')\n",
    "print('Recall', np.mean(recall), recall.std())\n",
    "precision = cross_val_score(rf, X_train, y_train, cv=3, scoring='precision')\n",
    "print('Precision', np.mean(precision), precision.std())\n",
    "f1 = cross_val_score(rf, X_train, y_train, cv=3, scoring='f1')\n",
    "print('F1', np.mean(f1), 'std',f1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pa = pathways[['Group', 'Age', 'Gender', 'BMI', 'Steps',\n",
    "       'path:hsa03040-mean', 'path:hsa03040-variance', 'path:hsa03050-mean',\n",
    "       'path:hsa03050-variance', 'path:hsa03060-mean',\n",
    "       'path:hsa03060-variance', 'path:hsa04130-mean',\n",
    "       'path:hsa04130-variance', 'path:hsa04141-mean',\n",
    "       'path:hsa04141-variance', 'path:hsa04662-mean',\n",
    "       'path:hsa04662-variance', 'path:hsa05220-mean',\n",
    "       'path:hsa05220-variance']]\n",
    "Y_pa =pathways['Weight_loss_band']                  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pa,Y_pa, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random= RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, \n",
    "                               random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators = 273,\n",
    " min_samples_split = 5,\n",
    " min_samples_leaf = 3,\n",
    " max_features = 'sqrt',\n",
    " criterion = 'entropy',\n",
    " max_depth = 2,\n",
    " bootstrap = True)\n",
    "random_forest.fit(X_train,y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "importance = pd.Series(random_forest.feature_importances_, index=X_pa.columns)\n",
    "importance.nlargest(10).plot(kind='bar');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = list(range(1,300))\n",
    "\n",
    "d1_train_acc = []\n",
    "d1_test_acc = []\n",
    "d1_auc_score = []\n",
    "d1_prec_score = []\n",
    "d1_recall_score = []\n",
    "\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    X_pa = pathways[['Group', 'Age', 'Gender', 'BMI', 'Steps',\n",
    "       'path:hsa03040-mean', 'path:hsa03040-variance', 'path:hsa03050-mean',\n",
    "       'path:hsa03050-variance', 'path:hsa03060-mean',\n",
    "       'path:hsa03060-variance', 'path:hsa04130-mean',\n",
    "       'path:hsa04130-variance', 'path:hsa04141-mean',\n",
    "       'path:hsa04141-variance', 'path:hsa04662-mean',\n",
    "       'path:hsa04662-variance', 'path:hsa05220-mean',\n",
    "       'path:hsa05220-variance']]\n",
    "    Y_pa = pathways['Weight_loss_band']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_pa,Y_pa, test_size = 0.2, random_state = i) \n",
    "    \n",
    "    random_forest= RandomForestClassifier(n_estimators = 104,\n",
    "     min_samples_split = 10,\n",
    "     min_samples_leaf = 3,\n",
    "     max_features = 'auto',\n",
    "     max_depth = 2,\n",
    "     bootstrap =  False)\n",
    "    \n",
    "    random_forest.fit(X_train,y_train)\n",
    "    y_pred = random_forest.predict(X_test) \n",
    "\n",
    "    rf_train_acc = random_forest.score(X_train, y_train)\n",
    "    rf_test_acc = accuracy_score(y_test,y_pred)\n",
    "    auc_score = roc_auc_score(y_test,y_pred)\n",
    "    prec_score = average_precision_score(y_test, y_pred)\n",
    "    rec_score = recall_score(y_test,y_pred)\n",
    "\n",
    "    d1_train_acc.append(rf_train_acc)\n",
    "    d1_test_acc.append(rf_test_acc)\n",
    "    d1_auc_score.append(auc_score)\n",
    "    d1_prec_score.append(prec_score)\n",
    "    d1_recall_score.append(rec_score)\n",
    "    \n",
    "\n",
    "print('Mean Training Accuracy:', np.mean(d1_train_acc)) \n",
    "print('Mean Test Accuracy:', np.mean(d1_test_acc))\n",
    "print(statistics.stdev(d1_test_acc))\n",
    "\n",
    "print('AUC score equals',np.mean(d1_auc_score))\n",
    "print('Standard Deviation for auc score',statistics.stdev(d1_auc_score))\n",
    "print('Average precision score:', np.mean(d1_prec_score))\n",
    "print('Average recall score', np.mean(d1_recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf,X_train,y_train, cv=3)\n",
    "scores               \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "lb = LabelBinarizer()\n",
    "y_train = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "\n",
    "recall = cross_val_score(rf, X_train, y_train, cv=3, scoring='recall')\n",
    "print('Recall', np.mean(recall), recall.std())\n",
    "precision = cross_val_score(rf, X_train, y_train, cv=3, scoring='precision')\n",
    "print('Precision', np.mean(precision), precision.std())\n",
    "f1 = cross_val_score(rf, X_train, y_train, cv=3, scoring='f1')\n",
    "print('F1', np.mean(f1), 'std',f1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra model without some pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = list(range(1,300))\n",
    "\n",
    "d1_train_acc = []\n",
    "d1_test_acc = []\n",
    "d1_auc_score = []\n",
    "d1_prec_score = []\n",
    "d1_recall_score = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    X_pa = pathways[['Group', 'Age', 'Gender', 'BMI', 'Steps',\n",
    "       'path:hsa03040-mean', 'path:hsa03040-variance', 'path:hsa03050-mean',\n",
    "       'path:hsa03050-variance', 'path:hsa03060-mean',\n",
    "       'path:hsa03060-variance']]\n",
    "    Y_pa = pathways['Weight_loss_band']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_pa,Y_pa, test_size = 0.2, random_state = i) \n",
    "    \n",
    "    random_forest= RandomForestClassifier(n_estimators = 104,\n",
    "     min_samples_split = 10,\n",
    "     min_samples_leaf = 3,\n",
    "     max_features = 'auto',\n",
    "     max_depth = 2,\n",
    "     bootstrap =  False)\n",
    "    \n",
    "    random_forest.fit(X_train,y_train)\n",
    "    y_pred = random_forest.predict(X_test) \n",
    "\n",
    "    rf_train_acc = random_forest.score(X_train, y_train)\n",
    "    rf_test_acc = accuracy_score(y_test,y_pred)\n",
    "    auc_score = roc_auc_score(y_test,y_pred)\n",
    "    prec_score = average_precision_score(y_test, y_pred)\n",
    "    rec_score = recall_score(y_test,y_pred)\n",
    "\n",
    "    d1_train_acc.append(rf_train_acc)\n",
    "    d1_test_acc.append(rf_test_acc)\n",
    "    d1_auc_score.append(auc_score)\n",
    "    d1_prec_score.append(prec_score)\n",
    "    d1_recall_score.append(rec_score)\n",
    "\n",
    "print('Mean Training Accuracy:', np.mean(d1_train_acc)) \n",
    "print('Mean Test Accuracy:', np.mean(d1_test_acc))\n",
    "print(statistics.stdev(d1_test_acc))\n",
    "\n",
    "print('AUC score equals',np.mean(d1_auc_score))\n",
    "print('Standard Deviation for auc score',statistics.stdev(d1_auc_score))\n",
    "print('Average precision score:', np.mean(d1_prec_score))\n",
    "print('Average recall score', np.mean(d1_recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf,X_train,y_train, cv=5)\n",
    "scores               \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "lb = LabelBinarizer()\n",
    "y_train = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "\n",
    "recall = cross_val_score(rf, X_train, y_train, cv=3, scoring='recall')\n",
    "print('Recall', np.mean(recall), recall.std())\n",
    "precision = cross_val_score(rf, X_train, y_train, cv=3, scoring='precision')\n",
    "print('Precision', np.mean(precision), precision.std())\n",
    "f1 = cross_val_score(rf, X_train, y_train, cv=3, scoring='f1')\n",
    "print('F1', np.mean(f1), 'std',f1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= pcs[['PC1', 'PC2', 'PC3', 'PC4', 'PC5','Steps','Gender','BMI']]\n",
    "Y = pcs['Weight_loss_band']                \n",
    "X_train, X_test, y_train, y_test= train_test_split(X,Y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf_random= RandomizedSearchCV(estimator = rf, param_distributions = random_grid, \n",
    "                               n_iter = 100, cv = 3, verbose=2, \n",
    "                               random_state=42, n_jobs = -1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest= RandomForestClassifier(n_estimators = 315,\n",
    " min_samples_split = 7,\n",
    " min_samples_leaf = 2,\n",
    " max_features = 'auto',\n",
    " max_depth = 14,\n",
    " bootstrap = False , random_state = 42)\n",
    "random_forest.fit(X_train,y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "importance = pd.Series(random_forest.feature_importances_, index=X.columns)\n",
    "importance.nlargest(10).plot(kind='bar');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = list(range(1,300))\n",
    "\n",
    "d1_train_acc = []\n",
    "d1_test_acc = []\n",
    "d1_auc_score = []\n",
    "d1_prec_score = []\n",
    "d1_recall_score = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    X_pcs = pcs[['PC3', 'PC2', 'PC5', 'Gender', 'BMI', 'Steps']]\n",
    "    Y_pcs = pcs['Weight_loss_band']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X_pcs,Y_pcs, test_size = 0.2, random_state = i) \n",
    "    \n",
    "    random_forest= RandomForestClassifier(n_estimators = 315,\n",
    "     min_samples_split = 7,\n",
    "     min_samples_leaf = 2,\n",
    "     max_features = 'auto',\n",
    "     max_depth = 14,\n",
    "     bootstrap = False)\n",
    "    \n",
    "    random_forest.fit(X_train,y_train)\n",
    "    y_pred = random_forest.predict(X_test) \n",
    "\n",
    "    rf_train_acc = random_forest.score(X_train, y_train)\n",
    "    rf_test_acc = accuracy_score(y_test,y_pred)\n",
    "    auc_score = roc_auc_score(y_test,y_pred)\n",
    "    prec_score = average_precision_score(y_test, y_pred)\n",
    "    rec_score = recall_score(y_test,y_pred)\n",
    "\n",
    "    d1_train_acc.append(rf_train_acc)\n",
    "    d1_test_acc.append(rf_test_acc)\n",
    "    d1_auc_score.append(auc_score)\n",
    "    d1_prec_score.append(prec_score)\n",
    "    d1_recall_score.append(rec_score)\n",
    "\n",
    "print('Mean Training Accuracy:', np.mean(d1_train_acc)) \n",
    "print('Mean Test Accuracy:', np.mean(d1_test_acc))\n",
    "print(statistics.stdev(d1_test_acc))\n",
    "\n",
    "print('AUC score equals',np.mean(d1_auc_score))\n",
    "print('Standard Deviation for auc score',statistics.stdev(d1_auc_score))\n",
    "print('Average precision score:', np.mean(d1_prec_score))\n",
    "print('Average recall score', np.mean(d1_recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(rf,X_train,y_train, cv=5)\n",
    "scores               \n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "lb = LabelBinarizer()\n",
    "y_train = np.array([number[0] for number in lb.fit_transform(y_train)])\n",
    "\n",
    "recall = cross_val_score(rf, X_train, y_train, cv=3, scoring='recall')\n",
    "print('Recall', np.mean(recall), recall.std())\n",
    "precision = cross_val_score(rf, X_train, y_train, cv=3, scoring='precision')\n",
    "print('Precision', np.mean(precision), precision.std())\n",
    "f1 = cross_val_score(rf, X_train, y_train, cv=3, scoring='f1')\n",
    "print('F1', np.mean(f1), 'std',f1.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

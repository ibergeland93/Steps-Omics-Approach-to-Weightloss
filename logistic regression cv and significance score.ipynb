{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Filter out warnings\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= pd.read_csv('demo_steps_pca.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studyID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Weight_loss_band</th>\n",
       "      <th>Steps</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>36.24</td>\n",
       "      <td>1</td>\n",
       "      <td>10723.455560</td>\n",
       "      <td>8.061646</td>\n",
       "      <td>-5.761836</td>\n",
       "      <td>-4.841193</td>\n",
       "      <td>-2.171323</td>\n",
       "      <td>-2.788218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>35.71</td>\n",
       "      <td>0</td>\n",
       "      <td>4654.916667</td>\n",
       "      <td>8.430937</td>\n",
       "      <td>6.946562</td>\n",
       "      <td>1.794457</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>-3.024961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>42.80</td>\n",
       "      <td>0</td>\n",
       "      <td>5675.133333</td>\n",
       "      <td>8.256683</td>\n",
       "      <td>8.288072</td>\n",
       "      <td>2.570019</td>\n",
       "      <td>-0.302641</td>\n",
       "      <td>-3.554665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>26.72</td>\n",
       "      <td>1</td>\n",
       "      <td>9855.843373</td>\n",
       "      <td>8.376866</td>\n",
       "      <td>-0.916554</td>\n",
       "      <td>-6.212482</td>\n",
       "      <td>1.182002</td>\n",
       "      <td>-0.328640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>43.89</td>\n",
       "      <td>0</td>\n",
       "      <td>7595.388889</td>\n",
       "      <td>8.258802</td>\n",
       "      <td>0.870977</td>\n",
       "      <td>4.219331</td>\n",
       "      <td>0.654543</td>\n",
       "      <td>-3.580225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   studyID  Group  Age  Gender    BMI  Weight_loss_band         Steps  \\\n",
       "0     2001      0   28       0  36.24                 1  10723.455560   \n",
       "1     2002      1   38       1  35.71                 0   4654.916667   \n",
       "2     2003      0   26       1  42.80                 0   5675.133333   \n",
       "3     2004      1   60       0  26.72                 1   9855.843373   \n",
       "4     2006      1   48       1  43.89                 0   7595.388889   \n",
       "\n",
       "        PC1       PC2       PC3       PC4       PC5  \n",
       "0  8.061646 -5.761836 -4.841193 -2.171323 -2.788218  \n",
       "1  8.430937  6.946562  1.794457 -0.015105 -3.024961  \n",
       "2  8.256683  8.288072  2.570019 -0.302641 -3.554665  \n",
       "3  8.376866 -0.916554 -6.212482  1.182002 -0.328640  \n",
       "4  8.258802  0.870977  4.219331  0.654543 -3.580225  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df1.drop('Weight_loss_band', axis=1)\n",
    "y = df1['Weight_loss_band']  \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 0.7142857142857143\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.81      0.79        37\n",
      "          1       0.59      0.53      0.56        19\n",
      "\n",
      "avg / total       0.71      0.71      0.71        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics, cross_validation\n",
    "predicted = cross_validation.cross_val_predict(logreg, X, y, cv=3)\n",
    "print(\"Average accuracy:\",metrics.accuracy_score(y, predicted))\n",
    "print(metrics.classification_report(y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7954545454545454\n",
      "logreg test accuracy=  0.75\n"
     ]
    }
   ],
   "source": [
    "#random4\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df1, test_size=0.2, random_state=300)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.88745874e-03,  5.28418803e-01, -2.37294275e-03,\n",
       "         4.44436579e-01,  4.30704331e-03,  3.45002231e-04,\n",
       "         1.14067396e-01, -1.05877345e-01, -2.03786278e-01,\n",
       "        -3.14327369e-03,  2.13882187e-01]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.461061\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>Weight_loss_band</td> <th>  No. Observations:  </th>  <td>    44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.2629</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:26:59</td>     <th>  Log-Likelihood:    </th> <td> -20.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -27.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.1526</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studyID</th> <td>   -0.0095</td> <td>    0.012</td> <td>   -0.781</td> <td> 0.435</td> <td>   -0.033</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group</th>   <td>    0.8617</td> <td>    0.919</td> <td>    0.938</td> <td> 0.348</td> <td>   -0.939</td> <td>    2.662</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>     <td>    0.0008</td> <td>    0.036</td> <td>    0.023</td> <td> 0.982</td> <td>   -0.070</td> <td>    0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>  <td>    0.9147</td> <td>    0.949</td> <td>    0.964</td> <td> 0.335</td> <td>   -0.945</td> <td>    2.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>     <td>    0.0236</td> <td>    0.111</td> <td>    0.212</td> <td> 0.832</td> <td>   -0.195</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steps</th>   <td>    0.0004</td> <td>    0.000</td> <td>    1.953</td> <td> 0.051</td> <td>-1.41e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>     <td>    1.5593</td> <td>    2.994</td> <td>    0.521</td> <td> 0.603</td> <td>   -4.309</td> <td>    7.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>     <td>   -0.1479</td> <td>    0.178</td> <td>   -0.830</td> <td> 0.406</td> <td>   -0.497</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>     <td>   -0.2182</td> <td>    0.163</td> <td>   -1.335</td> <td> 0.182</td> <td>   -0.538</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>     <td>    0.0278</td> <td>    0.235</td> <td>    0.118</td> <td> 0.906</td> <td>   -0.433</td> <td>    0.489</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>     <td>    0.2050</td> <td>    0.222</td> <td>    0.925</td> <td> 0.355</td> <td>   -0.230</td> <td>    0.640</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:       Weight_loss_band   No. Observations:                   44\n",
       "Model:                          Logit   Df Residuals:                       33\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.2629\n",
       "Time:                        12:26:59   Log-Likelihood:                -20.287\n",
       "converged:                       True   LL-Null:                       -27.522\n",
       "                                        LLR p-value:                    0.1526\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "studyID       -0.0095      0.012     -0.781      0.435      -0.033       0.014\n",
       "Group          0.8617      0.919      0.938      0.348      -0.939       2.662\n",
       "Age            0.0008      0.036      0.023      0.982      -0.070       0.072\n",
       "Gender         0.9147      0.949      0.964      0.335      -0.945       2.775\n",
       "BMI            0.0236      0.111      0.212      0.832      -0.195       0.242\n",
       "Steps          0.0004      0.000      1.953      0.051   -1.41e-06       0.001\n",
       "PC1            1.5593      2.994      0.521      0.603      -4.309       7.428\n",
       "PC2           -0.1479      0.178     -0.830      0.406      -0.497       0.201\n",
       "PC3           -0.2182      0.163     -1.335      0.182      -0.538       0.102\n",
       "PC4            0.0278      0.235      0.118      0.906      -0.433       0.489\n",
       "PC5            0.2050      0.222      0.925      0.355      -0.230       0.640\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9090909090909091\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random5\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df1, test_size=0.2, random_state=368)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID   -0.084064\n",
       "Group      0.407859\n",
       "Age        0.098866\n",
       "Gender     0.492763\n",
       "BMI        0.144139\n",
       "Steps      0.934747\n",
       "PC1        0.012257\n",
       "PC2       -1.393012\n",
       "PC3       -1.894124\n",
       "PC4       -0.042253\n",
       "PC5        1.307499\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.234130\n",
      "         Iterations 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>Weight_loss_band</td> <th>  No. Observations:  </th>  <td>    44</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    33</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.6490</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:27:01</td>     <th>  Log-Likelihood:    </th> <td> -10.302</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -29.352</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>3.645e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studyID</th> <td>   -0.0058</td> <td>    0.019</td> <td>   -0.305</td> <td> 0.760</td> <td>   -0.043</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group</th>   <td>    3.1581</td> <td>    2.158</td> <td>    1.464</td> <td> 0.143</td> <td>   -1.071</td> <td>    7.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>     <td>    0.0244</td> <td>    0.056</td> <td>    0.433</td> <td> 0.665</td> <td>   -0.086</td> <td>    0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>  <td>    4.0734</td> <td>    2.619</td> <td>    1.555</td> <td> 0.120</td> <td>   -1.061</td> <td>    9.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>     <td>    0.3499</td> <td>    0.377</td> <td>    0.927</td> <td> 0.354</td> <td>   -0.390</td> <td>    1.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steps</th>   <td>    0.0005</td> <td>    0.000</td> <td>    1.923</td> <td> 0.054</td> <td>-1.04e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>     <td>   -1.2723</td> <td>    4.769</td> <td>   -0.267</td> <td> 0.790</td> <td>  -10.620</td> <td>    8.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>     <td>   -0.4033</td> <td>    0.342</td> <td>   -1.178</td> <td> 0.239</td> <td>   -1.074</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>     <td>   -1.1385</td> <td>    0.488</td> <td>   -2.335</td> <td> 0.020</td> <td>   -2.094</td> <td>   -0.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>     <td>   -0.2316</td> <td>    0.465</td> <td>   -0.498</td> <td> 0.618</td> <td>   -1.143</td> <td>    0.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>     <td>    1.3628</td> <td>    0.766</td> <td>    1.780</td> <td> 0.075</td> <td>   -0.138</td> <td>    2.864</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:       Weight_loss_band   No. Observations:                   44\n",
       "Model:                          Logit   Df Residuals:                       33\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.6490\n",
       "Time:                        12:27:01   Log-Likelihood:                -10.302\n",
       "converged:                       True   LL-Null:                       -29.352\n",
       "                                        LLR p-value:                 3.645e-05\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "studyID       -0.0058      0.019     -0.305      0.760      -0.043       0.031\n",
       "Group          3.1581      2.158      1.464      0.143      -1.071       7.387\n",
       "Age            0.0244      0.056      0.433      0.665      -0.086       0.135\n",
       "Gender         4.0734      2.619      1.555      0.120      -1.061       9.207\n",
       "BMI            0.3499      0.377      0.927      0.354      -0.390       1.089\n",
       "Steps          0.0005      0.000      1.923      0.054   -1.04e-05       0.001\n",
       "PC1           -1.2723      4.769     -0.267      0.790     -10.620       8.075\n",
       "PC2           -0.4033      0.342     -1.178      0.239      -1.074       0.268\n",
       "PC3           -1.1385      0.488     -2.335      0.020      -2.094      -0.183\n",
       "PC4           -0.2316      0.465     -0.498      0.618      -1.143       0.680\n",
       "PC5            1.3628      0.766      1.780      0.075      -0.138       2.864\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8181818181818182\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random6\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df1, test_size=0.2, random_state=400)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID   -0.049147\n",
       "Group      0.261449\n",
       "Age        0.732507\n",
       "Gender     0.250610\n",
       "BMI       -0.284920\n",
       "Steps      0.603416\n",
       "PC1       -0.007409\n",
       "PC2       -0.908001\n",
       "PC3       -0.744456\n",
       "PC4        0.779015\n",
       "PC5        0.848250\n",
       "dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.371024\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>Weight_loss_band</td> <th>  No. Observations:  </th>  <td>    44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.4068</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:27:01</td>     <th>  Log-Likelihood:    </th> <td> -16.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -27.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.01322</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studyID</th> <td>    0.0005</td> <td>    0.017</td> <td>    0.029</td> <td> 0.977</td> <td>   -0.032</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group</th>   <td>    0.9738</td> <td>    1.031</td> <td>    0.944</td> <td> 0.345</td> <td>   -1.048</td> <td>    2.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>     <td>    0.0626</td> <td>    0.042</td> <td>    1.485</td> <td> 0.138</td> <td>   -0.020</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>  <td>    1.1796</td> <td>    1.152</td> <td>    1.024</td> <td> 0.306</td> <td>   -1.078</td> <td>    3.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>     <td>   -0.0315</td> <td>    0.150</td> <td>   -0.210</td> <td> 0.834</td> <td>   -0.325</td> <td>    0.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steps</th>   <td>    0.0003</td> <td>    0.000</td> <td>    1.332</td> <td> 0.183</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>     <td>   -0.9307</td> <td>    4.019</td> <td>   -0.232</td> <td> 0.817</td> <td>   -8.807</td> <td>    6.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>     <td>   -0.2335</td> <td>    0.237</td> <td>   -0.983</td> <td> 0.325</td> <td>   -0.699</td> <td>    0.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>     <td>   -0.3305</td> <td>    0.224</td> <td>   -1.477</td> <td> 0.140</td> <td>   -0.769</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>     <td>    0.3083</td> <td>    0.294</td> <td>    1.049</td> <td> 0.294</td> <td>   -0.268</td> <td>    0.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>     <td>    0.5126</td> <td>    0.300</td> <td>    1.709</td> <td> 0.088</td> <td>   -0.075</td> <td>    1.101</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:       Weight_loss_band   No. Observations:                   44\n",
       "Model:                          Logit   Df Residuals:                       33\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.4068\n",
       "Time:                        12:27:01   Log-Likelihood:                -16.325\n",
       "converged:                       True   LL-Null:                       -27.522\n",
       "                                        LLR p-value:                   0.01322\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "studyID        0.0005      0.017      0.029      0.977      -0.032       0.033\n",
       "Group          0.9738      1.031      0.944      0.345      -1.048       2.995\n",
       "Age            0.0626      0.042      1.485      0.138      -0.020       0.145\n",
       "Gender         1.1796      1.152      1.024      0.306      -1.078       3.437\n",
       "BMI           -0.0315      0.150     -0.210      0.834      -0.325       0.262\n",
       "Steps          0.0003      0.000      1.332      0.183      -0.000       0.001\n",
       "PC1           -0.9307      4.019     -0.232      0.817      -8.807       6.946\n",
       "PC2           -0.2335      0.237     -0.983      0.325      -0.699       0.232\n",
       "PC3           -0.3305      0.224     -1.477      0.140      -0.769       0.108\n",
       "PC4            0.3083      0.294      1.049      0.294      -0.268       0.885\n",
       "PC5            0.5126      0.300      1.709      0.088      -0.075       1.101\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8181818181818182\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random7\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df1, test_size=0.2, random_state=500)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID   -0.055049\n",
       "Group      0.387063\n",
       "Age        0.470638\n",
       "Gender     0.230741\n",
       "BMI        0.056101\n",
       "Steps      0.497440\n",
       "PC1       -0.008357\n",
       "PC2       -1.448280\n",
       "PC3       -0.572520\n",
       "PC4        0.765824\n",
       "PC5        0.931958\n",
       "dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.333154\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>Weight_loss_band</td> <th>  No. Observations:  </th>  <td>    44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.4808</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:27:02</td>     <th>  Log-Likelihood:    </th> <td> -14.659</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -28.232</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>0.002469</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studyID</th> <td>    0.0072</td> <td>    0.017</td> <td>    0.423</td> <td> 0.672</td> <td>   -0.026</td> <td>    0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group</th>   <td>    1.9407</td> <td>    1.115</td> <td>    1.741</td> <td> 0.082</td> <td>   -0.245</td> <td>    4.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>     <td>    0.0432</td> <td>    0.041</td> <td>    1.052</td> <td> 0.293</td> <td>   -0.037</td> <td>    0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>  <td>    1.3670</td> <td>    1.270</td> <td>    1.077</td> <td> 0.282</td> <td>   -1.121</td> <td>    3.855</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>     <td>    0.0790</td> <td>    0.167</td> <td>    0.472</td> <td> 0.637</td> <td>   -0.249</td> <td>    0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steps</th>   <td>    0.0003</td> <td>    0.000</td> <td>    1.352</td> <td> 0.176</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>     <td>   -2.9089</td> <td>    4.219</td> <td>   -0.689</td> <td> 0.491</td> <td>  -11.178</td> <td>    5.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>     <td>   -0.3006</td> <td>    0.234</td> <td>   -1.286</td> <td> 0.198</td> <td>   -0.759</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>     <td>   -0.2536</td> <td>    0.200</td> <td>   -1.271</td> <td> 0.204</td> <td>   -0.645</td> <td>    0.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>     <td>    0.1948</td> <td>    0.312</td> <td>    0.624</td> <td> 0.532</td> <td>   -0.417</td> <td>    0.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>     <td>    0.6685</td> <td>    0.364</td> <td>    1.837</td> <td> 0.066</td> <td>   -0.045</td> <td>    1.382</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:       Weight_loss_band   No. Observations:                   44\n",
       "Model:                          Logit   Df Residuals:                       33\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.4808\n",
       "Time:                        12:27:02   Log-Likelihood:                -14.659\n",
       "converged:                       True   LL-Null:                       -28.232\n",
       "                                        LLR p-value:                  0.002469\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "studyID        0.0072      0.017      0.423      0.672      -0.026       0.041\n",
       "Group          1.9407      1.115      1.741      0.082      -0.245       4.126\n",
       "Age            0.0432      0.041      1.052      0.293      -0.037       0.124\n",
       "Gender         1.3670      1.270      1.077      0.282      -1.121       3.855\n",
       "BMI            0.0790      0.167      0.472      0.637      -0.249       0.407\n",
       "Steps          0.0003      0.000      1.352      0.176      -0.000       0.001\n",
       "PC1           -2.9089      4.219     -0.689      0.491     -11.178       5.360\n",
       "PC2           -0.3006      0.234     -1.286      0.198      -0.759       0.158\n",
       "PC3           -0.2536      0.200     -1.271      0.204      -0.645       0.137\n",
       "PC4            0.1948      0.312      0.624      0.532      -0.417       0.806\n",
       "PC5            0.6685      0.364      1.837      0.066      -0.045       1.382\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8636363636363636\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random8\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df1, test_size=0.2, random_state=600)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.353131\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>Weight_loss_band</td> <th>  No. Observations:  </th>  <td>    44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.4613</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:27:03</td>     <th>  Log-Likelihood:    </th> <td> -15.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -28.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>0.003004</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studyID</th> <td>   -0.0128</td> <td>    0.018</td> <td>   -0.728</td> <td> 0.466</td> <td>   -0.047</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group</th>   <td>    1.3322</td> <td>    1.045</td> <td>    1.275</td> <td> 0.202</td> <td>   -0.716</td> <td>    3.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>     <td>    0.0633</td> <td>    0.056</td> <td>    1.132</td> <td> 0.258</td> <td>   -0.046</td> <td>    0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>  <td>    2.0454</td> <td>    1.251</td> <td>    1.635</td> <td> 0.102</td> <td>   -0.407</td> <td>    4.497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>     <td>    0.1078</td> <td>    0.123</td> <td>    0.876</td> <td> 0.381</td> <td>   -0.133</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steps</th>   <td>    0.0006</td> <td>    0.000</td> <td>    2.155</td> <td> 0.031</td> <td> 5.48e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>     <td>    1.3826</td> <td>    4.353</td> <td>    0.318</td> <td> 0.751</td> <td>   -7.148</td> <td>    9.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>     <td>   -0.3774</td> <td>    0.261</td> <td>   -1.448</td> <td> 0.148</td> <td>   -0.888</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>     <td>   -0.3728</td> <td>    0.197</td> <td>   -1.891</td> <td> 0.059</td> <td>   -0.759</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>     <td>    0.1781</td> <td>    0.327</td> <td>    0.544</td> <td> 0.586</td> <td>   -0.463</td> <td>    0.819</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>     <td>    0.3130</td> <td>    0.279</td> <td>    1.120</td> <td> 0.263</td> <td>   -0.235</td> <td>    0.861</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:       Weight_loss_band   No. Observations:                   44\n",
       "Model:                          Logit   Df Residuals:                       33\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.4613\n",
       "Time:                        12:27:03   Log-Likelihood:                -15.538\n",
       "converged:                       True   LL-Null:                       -28.841\n",
       "                                        LLR p-value:                  0.003004\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "studyID       -0.0128      0.018     -0.728      0.466      -0.047       0.022\n",
       "Group          1.3322      1.045      1.275      0.202      -0.716       3.381\n",
       "Age            0.0633      0.056      1.132      0.258      -0.046       0.173\n",
       "Gender         2.0454      1.251      1.635      0.102      -0.407       4.497\n",
       "BMI            0.1078      0.123      0.876      0.381      -0.133       0.349\n",
       "Steps          0.0006      0.000      2.155      0.031    5.48e-05       0.001\n",
       "PC1            1.3826      4.353      0.318      0.751      -7.148       9.913\n",
       "PC2           -0.3774      0.261     -1.448      0.148      -0.888       0.133\n",
       "PC3           -0.3728      0.197     -1.891      0.059      -0.759       0.014\n",
       "PC4            0.1781      0.327      0.544      0.586      -0.463       0.819\n",
       "PC5            0.3130      0.279      1.120      0.263      -0.235       0.861\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7727272727272727\n",
      "logreg test accuracy=  0.75\n"
     ]
    }
   ],
   "source": [
    "#random9\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df1, test_size=0.2, random_state=700)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.444306\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>Weight_loss_band</td> <th>  No. Observations:  </th>  <td>    44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.3222</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:27:06</td>     <th>  Log-Likelihood:    </th> <td> -19.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -28.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.04588</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studyID</th> <td>   -0.0076</td> <td>    0.014</td> <td>   -0.561</td> <td> 0.575</td> <td>   -0.034</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group</th>   <td>    1.8282</td> <td>    0.980</td> <td>    1.865</td> <td> 0.062</td> <td>   -0.093</td> <td>    3.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>     <td>    0.0456</td> <td>    0.034</td> <td>    1.338</td> <td> 0.181</td> <td>   -0.021</td> <td>    0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>  <td>    0.2966</td> <td>    0.960</td> <td>    0.309</td> <td> 0.757</td> <td>   -1.586</td> <td>    2.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>     <td>   -0.1364</td> <td>    0.144</td> <td>   -0.947</td> <td> 0.343</td> <td>   -0.419</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steps</th>   <td>    0.0003</td> <td>    0.000</td> <td>    1.442</td> <td> 0.149</td> <td>-9.01e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>     <td>    1.5345</td> <td>    3.352</td> <td>    0.458</td> <td> 0.647</td> <td>   -5.035</td> <td>    8.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>     <td>   -0.1201</td> <td>    0.219</td> <td>   -0.548</td> <td> 0.583</td> <td>   -0.549</td> <td>    0.309</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>     <td>   -0.1256</td> <td>    0.162</td> <td>   -0.777</td> <td> 0.437</td> <td>   -0.442</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>     <td>    0.0958</td> <td>    0.234</td> <td>    0.409</td> <td> 0.683</td> <td>   -0.364</td> <td>    0.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>     <td>    0.1434</td> <td>    0.240</td> <td>    0.599</td> <td> 0.549</td> <td>   -0.326</td> <td>    0.613</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:       Weight_loss_band   No. Observations:                   44\n",
       "Model:                          Logit   Df Residuals:                       33\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.3222\n",
       "Time:                        12:27:06   Log-Likelihood:                -19.549\n",
       "converged:                       True   LL-Null:                       -28.841\n",
       "                                        LLR p-value:                   0.04588\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "studyID       -0.0076      0.014     -0.561      0.575      -0.034       0.019\n",
       "Group          1.8282      0.980      1.865      0.062      -0.093       3.750\n",
       "Age            0.0456      0.034      1.338      0.181      -0.021       0.112\n",
       "Gender         0.2966      0.960      0.309      0.757      -1.586       2.179\n",
       "BMI           -0.1364      0.144     -0.947      0.343      -0.419       0.146\n",
       "Steps          0.0003      0.000      1.442      0.149   -9.01e-05       0.001\n",
       "PC1            1.5345      3.352      0.458      0.647      -5.035       8.105\n",
       "PC2           -0.1201      0.219     -0.548      0.583      -0.549       0.309\n",
       "PC3           -0.1256      0.162     -0.777      0.437      -0.442       0.191\n",
       "PC4            0.0958      0.234      0.409      0.683      -0.364       0.555\n",
       "PC5            0.1434      0.240      0.599      0.549      -0.326       0.613\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7727272727272727\n",
      "logreg test accuracy=  1.0\n"
     ]
    }
   ],
   "source": [
    "#random10\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df1, test_size=0.2, random_state=22)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.481951\n",
      "         Iterations 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>Weight_loss_band</td> <th>  No. Observations:  </th>  <td>    44</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    33</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>    10</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Tue, 23 Apr 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.2647</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>12:27:08</td>     <th>  Log-Likelihood:    </th> <td> -21.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -28.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.1225</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>studyID</th> <td>   -0.0041</td> <td>    0.014</td> <td>   -0.295</td> <td> 0.768</td> <td>   -0.031</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Group</th>   <td>    1.0872</td> <td>    0.848</td> <td>    1.282</td> <td> 0.200</td> <td>   -0.575</td> <td>    2.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>     <td>    0.0068</td> <td>    0.035</td> <td>    0.196</td> <td> 0.845</td> <td>   -0.061</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Gender</th>  <td>    0.7590</td> <td>    0.856</td> <td>    0.886</td> <td> 0.375</td> <td>   -0.919</td> <td>    2.437</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BMI</th>     <td>    0.0031</td> <td>    0.109</td> <td>    0.029</td> <td> 0.977</td> <td>   -0.210</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Steps</th>   <td>    0.0003</td> <td>    0.000</td> <td>    1.692</td> <td> 0.091</td> <td>-4.52e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC1</th>     <td>    0.3961</td> <td>    3.371</td> <td>    0.117</td> <td> 0.906</td> <td>   -6.211</td> <td>    7.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC2</th>     <td>   -0.1739</td> <td>    0.186</td> <td>   -0.934</td> <td> 0.351</td> <td>   -0.539</td> <td>    0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC3</th>     <td>   -0.2436</td> <td>    0.142</td> <td>   -1.716</td> <td> 0.086</td> <td>   -0.522</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC4</th>     <td>    0.0149</td> <td>    0.222</td> <td>    0.067</td> <td> 0.947</td> <td>   -0.421</td> <td>    0.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PC5</th>     <td>    0.2065</td> <td>    0.198</td> <td>    1.041</td> <td> 0.298</td> <td>   -0.182</td> <td>    0.595</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:       Weight_loss_band   No. Observations:                   44\n",
       "Model:                          Logit   Df Residuals:                       33\n",
       "Method:                           MLE   Df Model:                           10\n",
       "Date:                Tue, 23 Apr 2019   Pseudo R-squ.:                  0.2647\n",
       "Time:                        12:27:08   Log-Likelihood:                -21.206\n",
       "converged:                       True   LL-Null:                       -28.841\n",
       "                                        LLR p-value:                    0.1225\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "studyID       -0.0041      0.014     -0.295      0.768      -0.031       0.023\n",
       "Group          1.0872      0.848      1.282      0.200      -0.575       2.750\n",
       "Age            0.0068      0.035      0.196      0.845      -0.061       0.075\n",
       "Gender         0.7590      0.856      0.886      0.375      -0.919       2.437\n",
       "BMI            0.0031      0.109      0.029      0.977      -0.210       0.217\n",
       "Steps          0.0003      0.000      1.692      0.091   -4.52e-05       0.001\n",
       "PC1            0.3961      3.371      0.117      0.906      -6.211       7.004\n",
       "PC2           -0.1739      0.186     -0.934      0.351      -0.539       0.191\n",
       "PC3           -0.2436      0.142     -1.716      0.086      -0.522       0.035\n",
       "PC4            0.0149      0.222      0.067      0.947      -0.421       0.450\n",
       "PC5            0.2065      0.198      1.041      0.298      -0.182       0.595\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('KEGG_7pathways_steps.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studyID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Weight_loss_band</th>\n",
       "      <th>Steps</th>\n",
       "      <th>path:hsa03040-mean</th>\n",
       "      <th>path:hsa03040-variance</th>\n",
       "      <th>path:hsa03050-mean</th>\n",
       "      <th>...</th>\n",
       "      <th>path:hsa03060-mean</th>\n",
       "      <th>path:hsa03060-variance</th>\n",
       "      <th>path:hsa04130-mean</th>\n",
       "      <th>path:hsa04130-variance</th>\n",
       "      <th>path:hsa04141-mean</th>\n",
       "      <th>path:hsa04141-variance</th>\n",
       "      <th>path:hsa04662-mean</th>\n",
       "      <th>path:hsa04662-variance</th>\n",
       "      <th>path:hsa05220-mean</th>\n",
       "      <th>path:hsa05220-variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>36.24</td>\n",
       "      <td>1</td>\n",
       "      <td>10723.455560</td>\n",
       "      <td>86.154219</td>\n",
       "      <td>21800.778330</td>\n",
       "      <td>79.794511</td>\n",
       "      <td>...</td>\n",
       "      <td>72.230671</td>\n",
       "      <td>3886.474530</td>\n",
       "      <td>50.664777</td>\n",
       "      <td>1633.094649</td>\n",
       "      <td>98.424988</td>\n",
       "      <td>49954.700680</td>\n",
       "      <td>159.915149</td>\n",
       "      <td>37825.957920</td>\n",
       "      <td>107.235180</td>\n",
       "      <td>21103.621460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>35.71</td>\n",
       "      <td>0</td>\n",
       "      <td>4654.916667</td>\n",
       "      <td>97.584318</td>\n",
       "      <td>15007.706570</td>\n",
       "      <td>68.788322</td>\n",
       "      <td>...</td>\n",
       "      <td>101.742322</td>\n",
       "      <td>5646.975137</td>\n",
       "      <td>43.465865</td>\n",
       "      <td>1679.074231</td>\n",
       "      <td>84.057955</td>\n",
       "      <td>15199.893980</td>\n",
       "      <td>102.296825</td>\n",
       "      <td>9691.314802</td>\n",
       "      <td>73.110464</td>\n",
       "      <td>5785.362121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>42.80</td>\n",
       "      <td>0</td>\n",
       "      <td>5675.133333</td>\n",
       "      <td>95.057381</td>\n",
       "      <td>12617.681560</td>\n",
       "      <td>68.462327</td>\n",
       "      <td>...</td>\n",
       "      <td>102.477762</td>\n",
       "      <td>11260.700280</td>\n",
       "      <td>49.024537</td>\n",
       "      <td>1575.377166</td>\n",
       "      <td>82.168618</td>\n",
       "      <td>11999.813860</td>\n",
       "      <td>106.311380</td>\n",
       "      <td>13742.844300</td>\n",
       "      <td>74.360748</td>\n",
       "      <td>5684.006951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>26.72</td>\n",
       "      <td>1</td>\n",
       "      <td>9855.843373</td>\n",
       "      <td>88.907581</td>\n",
       "      <td>18117.487590</td>\n",
       "      <td>82.024351</td>\n",
       "      <td>...</td>\n",
       "      <td>82.144727</td>\n",
       "      <td>4236.446791</td>\n",
       "      <td>48.366668</td>\n",
       "      <td>2024.659491</td>\n",
       "      <td>97.786337</td>\n",
       "      <td>50042.642200</td>\n",
       "      <td>127.510289</td>\n",
       "      <td>20393.076990</td>\n",
       "      <td>87.864261</td>\n",
       "      <td>10414.037840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>43.89</td>\n",
       "      <td>0</td>\n",
       "      <td>7595.388889</td>\n",
       "      <td>84.981499</td>\n",
       "      <td>9910.820112</td>\n",
       "      <td>79.067493</td>\n",
       "      <td>...</td>\n",
       "      <td>96.999589</td>\n",
       "      <td>9473.002696</td>\n",
       "      <td>48.343406</td>\n",
       "      <td>1081.223172</td>\n",
       "      <td>75.811154</td>\n",
       "      <td>9582.504013</td>\n",
       "      <td>129.117374</td>\n",
       "      <td>18994.681880</td>\n",
       "      <td>80.114105</td>\n",
       "      <td>6362.957057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   studyID  Group  Age  Gender    BMI  Weight_loss_band         Steps  \\\n",
       "0     2001      0   28       0  36.24                 1  10723.455560   \n",
       "1     2002      1   38       1  35.71                 0   4654.916667   \n",
       "2     2003      0   26       1  42.80                 0   5675.133333   \n",
       "3     2004      1   60       0  26.72                 1   9855.843373   \n",
       "4     2006      1   48       1  43.89                 0   7595.388889   \n",
       "\n",
       "   path:hsa03040-mean  path:hsa03040-variance  path:hsa03050-mean  \\\n",
       "0           86.154219            21800.778330           79.794511   \n",
       "1           97.584318            15007.706570           68.788322   \n",
       "2           95.057381            12617.681560           68.462327   \n",
       "3           88.907581            18117.487590           82.024351   \n",
       "4           84.981499             9910.820112           79.067493   \n",
       "\n",
       "            ...            path:hsa03060-mean  path:hsa03060-variance  \\\n",
       "0           ...                     72.230671             3886.474530   \n",
       "1           ...                    101.742322             5646.975137   \n",
       "2           ...                    102.477762            11260.700280   \n",
       "3           ...                     82.144727             4236.446791   \n",
       "4           ...                     96.999589             9473.002696   \n",
       "\n",
       "   path:hsa04130-mean  path:hsa04130-variance  path:hsa04141-mean  \\\n",
       "0           50.664777             1633.094649           98.424988   \n",
       "1           43.465865             1679.074231           84.057955   \n",
       "2           49.024537             1575.377166           82.168618   \n",
       "3           48.366668             2024.659491           97.786337   \n",
       "4           48.343406             1081.223172           75.811154   \n",
       "\n",
       "   path:hsa04141-variance  path:hsa04662-mean  path:hsa04662-variance  \\\n",
       "0            49954.700680          159.915149            37825.957920   \n",
       "1            15199.893980          102.296825             9691.314802   \n",
       "2            11999.813860          106.311380            13742.844300   \n",
       "3            50042.642200          127.510289            20393.076990   \n",
       "4             9582.504013          129.117374            18994.681880   \n",
       "\n",
       "   path:hsa05220-mean  path:hsa05220-variance  \n",
       "0          107.235180            21103.621460  \n",
       "1           73.110464             5785.362121  \n",
       "2           74.360748             5684.006951  \n",
       "3           87.864261            10414.037840  \n",
       "4           80.114105             6362.957057  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9318181818181818\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random11\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=100)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID                   -1.421932\n",
       "Group                      0.246114\n",
       "Age                        0.160553\n",
       "Gender                    -0.062259\n",
       "BMI                       -1.482991\n",
       "Steps                      0.834131\n",
       "path:hsa03040-mean         2.896153\n",
       "path:hsa03040-variance    -1.826627\n",
       "path:hsa03050-mean         2.553379\n",
       "path:hsa03050-variance    -1.175787\n",
       "path:hsa03060-mean        -3.641468\n",
       "path:hsa03060-variance     1.792810\n",
       "path:hsa04130-mean         0.597447\n",
       "path:hsa04130-variance     0.301848\n",
       "path:hsa04141-mean         1.836932\n",
       "path:hsa04141-variance    -0.190816\n",
       "path:hsa04662-mean        10.495042\n",
       "path:hsa04662-variance    -9.533888\n",
       "path:hsa05220-mean        -1.354159\n",
       "path:hsa05220-variance     1.142587\n",
       "dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: inf\n",
      "         Iterations: 35\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-f15fbe5fcaea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m   1832\u001b[0m         bnryfit = super(Logit, self).fit(start_params=start_params,\n\u001b[0;32m   1833\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1834\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m   1835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m         \u001b[0mdiscretefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogitResults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbnryfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\discrete\\discrete_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, callback, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m         mlefit = super(DiscreteModel, self).fit(start_params=start_params,\n\u001b[0;32m    219\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                 disp=disp, callback=callback, **kwargs)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmlefit\u001b[0m \u001b[1;31m# up to subclasses to wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\statsmodels\\base\\model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, start_params, method, maxiter, full_output, disp, fargs, callback, retall, skip_hessian, **kwargs)\u001b[0m\n\u001b[0;32m    471\u001b[0m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcov_params_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             \u001b[0mHinv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mretvals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Hessian'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    474\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mskip_hessian\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[0msignature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'D->D'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'd->d'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[0mextobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_linalg_error_extobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[0mainv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_umath_linalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mainv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_singular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Singular matrix\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_raise_linalgerror_nonposdef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8863636363636364\n",
      "logreg test accuracy=  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#random12\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=122)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID                   -0.725738\n",
       "Group                      0.626172\n",
       "Age                        0.399254\n",
       "Gender                     0.144900\n",
       "BMI                       -0.665298\n",
       "Steps                      1.508957\n",
       "path:hsa03040-mean         0.312736\n",
       "path:hsa03040-variance    -1.322828\n",
       "path:hsa03050-mean         1.178664\n",
       "path:hsa03050-variance    -1.021117\n",
       "path:hsa03060-mean        -1.137834\n",
       "path:hsa03060-variance    -0.407807\n",
       "path:hsa04130-mean        -0.690561\n",
       "path:hsa04130-variance     0.732222\n",
       "path:hsa04141-mean         0.251605\n",
       "path:hsa04141-variance    -0.373926\n",
       "path:hsa04662-mean        11.897791\n",
       "path:hsa04662-variance   -10.109529\n",
       "path:hsa05220-mean        -1.773073\n",
       "path:hsa05220-variance     2.563133\n",
       "dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8636363636363636\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random13\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=200)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID                  -0.720426\n",
       "Group                     0.163579\n",
       "Age                       2.472381\n",
       "Gender                    0.021153\n",
       "BMI                      -0.279655\n",
       "Steps                     2.386143\n",
       "path:hsa03040-mean        1.942306\n",
       "path:hsa03040-variance   -2.010633\n",
       "path:hsa03050-mean       -0.025911\n",
       "path:hsa03050-variance   -0.207933\n",
       "path:hsa03060-mean       -1.574776\n",
       "path:hsa03060-variance   -1.609749\n",
       "path:hsa04130-mean        0.141284\n",
       "path:hsa04130-variance   -0.133543\n",
       "path:hsa04141-mean       -2.462137\n",
       "path:hsa04141-variance    3.348519\n",
       "path:hsa04662-mean        9.199127\n",
       "path:hsa04662-variance   -6.908859\n",
       "path:hsa05220-mean       -1.200894\n",
       "path:hsa05220-variance    2.854023\n",
       "dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8409090909090909\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random14\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=300)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID                  -0.411812\n",
       "Group                     0.099695\n",
       "Age                      -0.163936\n",
       "Gender                    0.044145\n",
       "BMI                      -0.443284\n",
       "Steps                     1.206391\n",
       "path:hsa03040-mean       -0.249614\n",
       "path:hsa03040-variance    0.030259\n",
       "path:hsa03050-mean        0.848067\n",
       "path:hsa03050-variance   -0.798114\n",
       "path:hsa03060-mean       -0.902334\n",
       "path:hsa03060-variance   -0.324763\n",
       "path:hsa04130-mean       -0.101436\n",
       "path:hsa04130-variance    0.705117\n",
       "path:hsa04141-mean       -0.422667\n",
       "path:hsa04141-variance   -0.298141\n",
       "path:hsa04662-mean        7.322404\n",
       "path:hsa04662-variance   -8.060345\n",
       "path:hsa05220-mean       -0.764038\n",
       "path:hsa05220-variance    2.054820\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  1.0\n",
      "logreg test accuracy=  0.5\n"
     ]
    }
   ],
   "source": [
    "#random15\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=368)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studyID                   -0.758674\n",
       "Group                      0.107461\n",
       "Age                       -1.556275\n",
       "Gender                     0.071065\n",
       "BMI                       -1.576673\n",
       "Steps                      3.025110\n",
       "path:hsa03040-mean        -2.452331\n",
       "path:hsa03040-variance    -2.244231\n",
       "path:hsa03050-mean         6.244396\n",
       "path:hsa03050-variance    -6.048773\n",
       "path:hsa03060-mean        -3.663855\n",
       "path:hsa03060-variance    -1.272730\n",
       "path:hsa04130-mean        -0.411716\n",
       "path:hsa04130-variance     0.232141\n",
       "path:hsa04141-mean         1.808209\n",
       "path:hsa04141-variance    -0.025571\n",
       "path:hsa04662-mean        15.533842\n",
       "path:hsa04662-variance    -9.868728\n",
       "path:hsa05220-mean        -3.272967\n",
       "path:hsa05220-variance     3.782063\n",
       "dtype: float64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef=logreg.coef_[0]\n",
    "\n",
    "len(np.std(X_train,0))\n",
    "\n",
    "np.std(X_train, 0) * (coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.75\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random16\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=400)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7954545454545454\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random17\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=500)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8409090909090909\n",
      "logreg test accuracy=  0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "#random18\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=600)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7954545454545454\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random19\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=700)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7045454545454546\n",
      "logreg test accuracy=  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#random20\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=22)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Logit(Y_train, X_train)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_excel('demo_steps_pca.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studyID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Weight_loss_band</th>\n",
       "      <th>Steps</th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>36.24</td>\n",
       "      <td>1</td>\n",
       "      <td>10723.455556</td>\n",
       "      <td>8.061646</td>\n",
       "      <td>-5.761836</td>\n",
       "      <td>-4.841193</td>\n",
       "      <td>-2.171323</td>\n",
       "      <td>-2.788218</td>\n",
       "      <td>2.032909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>35.71</td>\n",
       "      <td>0</td>\n",
       "      <td>4654.916667</td>\n",
       "      <td>8.430937</td>\n",
       "      <td>6.946562</td>\n",
       "      <td>1.794457</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>-3.024961</td>\n",
       "      <td>-0.200291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>42.80</td>\n",
       "      <td>0</td>\n",
       "      <td>5675.133333</td>\n",
       "      <td>8.256683</td>\n",
       "      <td>8.288072</td>\n",
       "      <td>2.570019</td>\n",
       "      <td>-0.302641</td>\n",
       "      <td>-3.554665</td>\n",
       "      <td>4.007124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>26.72</td>\n",
       "      <td>1</td>\n",
       "      <td>9855.843373</td>\n",
       "      <td>8.376866</td>\n",
       "      <td>-0.916554</td>\n",
       "      <td>-6.212482</td>\n",
       "      <td>1.182002</td>\n",
       "      <td>-0.328640</td>\n",
       "      <td>-1.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>43.89</td>\n",
       "      <td>0</td>\n",
       "      <td>7595.388889</td>\n",
       "      <td>8.258802</td>\n",
       "      <td>0.870977</td>\n",
       "      <td>4.219331</td>\n",
       "      <td>0.654543</td>\n",
       "      <td>-3.580225</td>\n",
       "      <td>1.235964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   studyID  Group  Age  Gender    BMI  Weight_loss_band         Steps  \\\n",
       "0     2001      0   28       0  36.24                 1  10723.455556   \n",
       "1     2002      1   38       1  35.71                 0   4654.916667   \n",
       "2     2003      0   26       1  42.80                 0   5675.133333   \n",
       "3     2004      1   60       0  26.72                 1   9855.843373   \n",
       "4     2006      1   48       1  43.89                 0   7595.388889   \n",
       "\n",
       "        PC1       PC2       PC3       PC4       PC5       PC6  \n",
       "0  8.061646 -5.761836 -4.841193 -2.171323 -2.788218  2.032909  \n",
       "1  8.430937  6.946562  1.794457 -0.015105 -3.024961 -0.200291  \n",
       "2  8.256683  8.288072  2.570019 -0.302641 -3.554665  4.007124  \n",
       "3  8.376866 -0.916554 -6.212482  1.182002 -0.328640 -1.162400  \n",
       "4  8.258802  0.870977  4.219331  0.654543 -3.580225  1.235964  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8409090909090909\n",
      "logreg test accuracy=  0.75\n"
     ]
    }
   ],
   "source": [
    "#random21\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=100)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9318181818181818\n",
      "logreg test accuracy=  0.75\n"
     ]
    }
   ],
   "source": [
    "#random22\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=122)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9090909090909091\n",
      "logreg test accuracy=  0.75\n"
     ]
    }
   ],
   "source": [
    "#random23\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=200)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8636363636363636\n",
      "logreg test accuracy=  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#random24\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=300)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9090909090909091\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random25\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=368)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8636363636363636\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random26\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=400)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8636363636363636\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random27\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=500)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8636363636363636\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random28\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=600)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7954545454545454\n",
      "logreg test accuracy=  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#random29\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=700)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.7954545454545454\n",
      "logreg test accuracy=  0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "#random30\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df2, test_size=0.2, random_state=22)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studyID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Weight_loss_band</th>\n",
       "      <th>Steps</th>\n",
       "      <th>path:hsa03040-mean</th>\n",
       "      <th>path:hsa03040-variance</th>\n",
       "      <th>path:hsa03050-mean</th>\n",
       "      <th>...</th>\n",
       "      <th>path:hsa03060-mean</th>\n",
       "      <th>path:hsa03060-variance</th>\n",
       "      <th>path:hsa04130-mean</th>\n",
       "      <th>path:hsa04130-variance</th>\n",
       "      <th>path:hsa04141-mean</th>\n",
       "      <th>path:hsa04141-variance</th>\n",
       "      <th>path:hsa04662-mean</th>\n",
       "      <th>path:hsa04662-variance</th>\n",
       "      <th>path:hsa05220-mean</th>\n",
       "      <th>path:hsa05220-variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>36.24</td>\n",
       "      <td>1</td>\n",
       "      <td>10723.455556</td>\n",
       "      <td>86.154219</td>\n",
       "      <td>21800.778325</td>\n",
       "      <td>79.794512</td>\n",
       "      <td>...</td>\n",
       "      <td>72.230671</td>\n",
       "      <td>3886.474530</td>\n",
       "      <td>50.664777</td>\n",
       "      <td>1633.094649</td>\n",
       "      <td>98.424988</td>\n",
       "      <td>49954.700683</td>\n",
       "      <td>159.915149</td>\n",
       "      <td>37825.957918</td>\n",
       "      <td>107.235180</td>\n",
       "      <td>21103.621464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>35.71</td>\n",
       "      <td>0</td>\n",
       "      <td>4654.916667</td>\n",
       "      <td>97.584318</td>\n",
       "      <td>15007.706572</td>\n",
       "      <td>68.788322</td>\n",
       "      <td>...</td>\n",
       "      <td>101.742322</td>\n",
       "      <td>5646.975137</td>\n",
       "      <td>43.465866</td>\n",
       "      <td>1679.074231</td>\n",
       "      <td>84.057955</td>\n",
       "      <td>15199.893980</td>\n",
       "      <td>102.296825</td>\n",
       "      <td>9691.314802</td>\n",
       "      <td>73.110464</td>\n",
       "      <td>5785.362121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>42.80</td>\n",
       "      <td>0</td>\n",
       "      <td>5675.133333</td>\n",
       "      <td>95.057381</td>\n",
       "      <td>12617.681555</td>\n",
       "      <td>68.462327</td>\n",
       "      <td>...</td>\n",
       "      <td>102.477762</td>\n",
       "      <td>11260.700282</td>\n",
       "      <td>49.024537</td>\n",
       "      <td>1575.377166</td>\n",
       "      <td>82.168618</td>\n",
       "      <td>11999.813861</td>\n",
       "      <td>106.311380</td>\n",
       "      <td>13742.844297</td>\n",
       "      <td>74.360748</td>\n",
       "      <td>5684.006951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>26.72</td>\n",
       "      <td>1</td>\n",
       "      <td>9855.843373</td>\n",
       "      <td>88.907581</td>\n",
       "      <td>18117.487593</td>\n",
       "      <td>82.024351</td>\n",
       "      <td>...</td>\n",
       "      <td>82.144727</td>\n",
       "      <td>4236.446791</td>\n",
       "      <td>48.366668</td>\n",
       "      <td>2024.659491</td>\n",
       "      <td>97.786337</td>\n",
       "      <td>50042.642204</td>\n",
       "      <td>127.510289</td>\n",
       "      <td>20393.076993</td>\n",
       "      <td>87.864261</td>\n",
       "      <td>10414.037841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>43.89</td>\n",
       "      <td>0</td>\n",
       "      <td>7595.388889</td>\n",
       "      <td>84.981499</td>\n",
       "      <td>9910.820112</td>\n",
       "      <td>79.067493</td>\n",
       "      <td>...</td>\n",
       "      <td>96.999589</td>\n",
       "      <td>9473.002696</td>\n",
       "      <td>48.343406</td>\n",
       "      <td>1081.223172</td>\n",
       "      <td>75.811154</td>\n",
       "      <td>9582.504013</td>\n",
       "      <td>129.117374</td>\n",
       "      <td>18994.681879</td>\n",
       "      <td>80.114105</td>\n",
       "      <td>6362.957057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   studyID  Group  Age  Gender    BMI  Weight_loss_band         Steps  \\\n",
       "0     2001      0   28       0  36.24                 1  10723.455556   \n",
       "1     2002      1   38       1  35.71                 0   4654.916667   \n",
       "2     2003      0   26       1  42.80                 0   5675.133333   \n",
       "3     2004      1   60       0  26.72                 1   9855.843373   \n",
       "4     2006      1   48       1  43.89                 0   7595.388889   \n",
       "\n",
       "   path:hsa03040-mean  path:hsa03040-variance  path:hsa03050-mean  \\\n",
       "0           86.154219            21800.778325           79.794512   \n",
       "1           97.584318            15007.706572           68.788322   \n",
       "2           95.057381            12617.681555           68.462327   \n",
       "3           88.907581            18117.487593           82.024351   \n",
       "4           84.981499             9910.820112           79.067493   \n",
       "\n",
       "            ...            path:hsa03060-mean  path:hsa03060-variance  \\\n",
       "0           ...                     72.230671             3886.474530   \n",
       "1           ...                    101.742322             5646.975137   \n",
       "2           ...                    102.477762            11260.700282   \n",
       "3           ...                     82.144727             4236.446791   \n",
       "4           ...                     96.999589             9473.002696   \n",
       "\n",
       "   path:hsa04130-mean  path:hsa04130-variance  path:hsa04141-mean  \\\n",
       "0           50.664777             1633.094649           98.424988   \n",
       "1           43.465866             1679.074231           84.057955   \n",
       "2           49.024537             1575.377166           82.168618   \n",
       "3           48.366668             2024.659491           97.786337   \n",
       "4           48.343406             1081.223172           75.811154   \n",
       "\n",
       "   path:hsa04141-variance  path:hsa04662-mean  path:hsa04662-variance  \\\n",
       "0            49954.700683          159.915149            37825.957918   \n",
       "1            15199.893980          102.296825             9691.314802   \n",
       "2            11999.813861          106.311380            13742.844297   \n",
       "3            50042.642204          127.510289            20393.076993   \n",
       "4             9582.504013          129.117374            18994.681879   \n",
       "\n",
       "   path:hsa05220-mean  path:hsa05220-variance  \n",
       "0          107.235180            21103.621464  \n",
       "1           73.110464             5785.362121  \n",
       "2           74.360748             5684.006951  \n",
       "3           87.864261            10414.037841  \n",
       "4           80.114105             6362.957057  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=pd.read_excel('demo_steps_kegg.xlsx')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8863636363636364\n",
      "logreg test accuracy=  0.5\n"
     ]
    }
   ],
   "source": [
    "#random31\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=100)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8863636363636364\n",
      "logreg test accuracy=  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#random32\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=122)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9318181818181818\n",
      "logreg test accuracy=  0.75\n"
     ]
    }
   ],
   "source": [
    "#random33\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=200)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8409090909090909\n",
      "logreg test accuracy=  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "#random34\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=300)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  1.0\n",
      "logreg test accuracy=  0.5\n"
     ]
    }
   ],
   "source": [
    "#random35\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=368)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9090909090909091\n",
      "logreg test accuracy=  0.5\n"
     ]
    }
   ],
   "source": [
    "#random36\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=400)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9318181818181818\n",
      "logreg test accuracy=  0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "#random37\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=500)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.8636363636363636\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random38\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=600)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9772727272727273\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random39\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=700)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg training acuracy=  0.9318181818181818\n",
      "logreg test accuracy=  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#random40\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=22)\n",
    "X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "Y_train = train_df['Weight_loss_band']  \n",
    "X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "Y_test = test_df['Weight_loss_band']  \n",
    "logreg = LogisticRegression()  \n",
    "logreg.fit(X_train, Y_train)\n",
    "logreg_train_acc = logreg.score(X_train, Y_train)\n",
    "logreg_test_acc = logreg.score(X_test, Y_test)\n",
    "print ('logreg training acuracy= ',logreg_train_acc)\n",
    "print('logreg test accuracy= ',logreg_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

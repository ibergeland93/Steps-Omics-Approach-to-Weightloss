{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Filter out warnings\n",
    "\n",
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spot Check Algorithm - helps with finding appropriate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined 60 models\n",
      ">0logistic: 0.709 (+/-0.047)\n",
      ">1logistic: 0.755 (+/-0.042)\n",
      ">2logistic: 0.690 (+/-0.025)\n",
      ">3logistic: 0.690 (+/-0.025)\n",
      ">0ridge-0.1: 0.755 (+/-0.042)\n",
      ">1ridge-0.1: 0.755 (+/-0.042)\n",
      ">2ridge-0.1: 0.755 (+/-0.042)\n",
      ">3ridge-0.1: 0.755 (+/-0.042)\n",
      ">0ridge-0.2: 0.755 (+/-0.042)\n",
      ">1ridge-0.2: 0.755 (+/-0.042)\n",
      ">2ridge-0.2: 0.732 (+/-0.021)\n",
      ">3ridge-0.2: 0.732 (+/-0.021)\n",
      ">0ridge-0.3: 0.755 (+/-0.042)\n",
      ">1ridge-0.3: 0.755 (+/-0.042)\n",
      ">2ridge-0.3: 0.732 (+/-0.021)\n",
      ">3ridge-0.3: 0.732 (+/-0.021)\n",
      ">0ridge-0.4: 0.755 (+/-0.042)\n",
      ">1ridge-0.4: 0.755 (+/-0.042)\n",
      ">2ridge-0.4: 0.732 (+/-0.021)\n",
      ">3ridge-0.4: 0.732 (+/-0.021)\n",
      ">0ridge-0.5: 0.755 (+/-0.042)\n",
      ">1ridge-0.5: 0.755 (+/-0.042)\n",
      ">2ridge-0.5: 0.732 (+/-0.021)\n",
      ">3ridge-0.5: 0.732 (+/-0.021)\n",
      ">0ridge-0.6: 0.755 (+/-0.042)\n",
      ">1ridge-0.6: 0.755 (+/-0.042)\n",
      ">2ridge-0.6: 0.732 (+/-0.021)\n",
      ">3ridge-0.6: 0.732 (+/-0.021)\n",
      ">0ridge-0.7: 0.755 (+/-0.042)\n",
      ">1ridge-0.7: 0.755 (+/-0.042)\n",
      ">2ridge-0.7: 0.732 (+/-0.021)\n",
      ">3ridge-0.7: 0.732 (+/-0.021)\n",
      ">0ridge-0.8: 0.755 (+/-0.042)\n",
      ">1ridge-0.8: 0.755 (+/-0.042)\n",
      ">2ridge-0.8: 0.732 (+/-0.021)\n",
      ">3ridge-0.8: 0.732 (+/-0.021)\n",
      ">0ridge-0.9: 0.755 (+/-0.042)\n",
      ">1ridge-0.9: 0.755 (+/-0.042)\n",
      ">2ridge-0.9: 0.732 (+/-0.021)\n",
      ">3ridge-0.9: 0.732 (+/-0.021)\n",
      ">0ridge-1.0: 0.755 (+/-0.042)\n",
      ">1ridge-1.0: 0.755 (+/-0.042)\n",
      ">2ridge-1.0: 0.732 (+/-0.021)\n",
      ">3ridge-1.0: 0.732 (+/-0.021)\n",
      ">0sgd: 0.437 (+/-0.139)\n",
      ">1sgd: 0.630 (+/-0.138)\n",
      ">2sgd: 0.622 (+/-0.098)\n",
      ">3sgd: 0.542 (+/-0.128)\n",
      ">0pa: 0.380 (+/-0.151)\n",
      ">1pa: 0.711 (+/-0.098)\n",
      ">2pa: 0.518 (+/-0.137)\n",
      ">3pa: 0.653 (+/-0.143)\n",
      ">0knn-1: 0.491 (+/-0.095)\n",
      ">1knn-1: 0.539 (+/-0.095)\n",
      ">2knn-1: 0.584 (+/-0.157)\n",
      ">3knn-1: 0.584 (+/-0.157)\n",
      ">0knn-2: 0.597 (+/-0.063)\n",
      ">1knn-2: 0.609 (+/-0.123)\n",
      ">2knn-2: 0.582 (+/-0.074)\n",
      ">3knn-2: 0.582 (+/-0.074)\n",
      ">0knn-3: 0.574 (+/-0.061)\n",
      ">1knn-3: 0.565 (+/-0.160)\n",
      ">2knn-3: 0.626 (+/-0.076)\n",
      ">3knn-3: 0.626 (+/-0.076)\n",
      ">0knn-4: 0.576 (+/-0.077)\n",
      ">1knn-4: 0.603 (+/-0.116)\n",
      ">2knn-4: 0.626 (+/-0.076)\n",
      ">3knn-4: 0.626 (+/-0.076)\n",
      ">0knn-5: 0.574 (+/-0.103)\n",
      ">1knn-5: 0.623 (+/-0.132)\n",
      ">2knn-5: 0.605 (+/-0.111)\n",
      ">3knn-5: 0.605 (+/-0.111)\n",
      ">0knn-6: 0.617 (+/-0.069)\n",
      ">1knn-6: 0.669 (+/-0.054)\n",
      ">2knn-6: 0.667 (+/-0.023)\n",
      ">3knn-6: 0.667 (+/-0.023)\n",
      ">0knn-7: 0.599 (+/-0.044)\n",
      ">1knn-7: 0.688 (+/-0.099)\n",
      ">2knn-7: 0.642 (+/-0.065)\n",
      ">3knn-7: 0.642 (+/-0.065)\n",
      ">0knn-8: 0.642 (+/-0.027)\n",
      ">1knn-8: 0.644 (+/-0.057)\n",
      ">2knn-8: 0.644 (+/-0.057)\n",
      ">3knn-8: 0.644 (+/-0.057)\n",
      ">0knn-9: 0.622 (+/-0.032)\n",
      ">1knn-9: 0.623 (+/-0.060)\n",
      ">2knn-9: 0.622 (+/-0.089)\n",
      ">3knn-9: 0.622 (+/-0.089)\n",
      ">0cart: 0.580 (+/-0.105)\n",
      ">1cart: 0.553 (+/-0.068)\n",
      ">2cart: 0.599 (+/-0.044)\n",
      ">3cart: 0.622 (+/-0.032)\n",
      ">0extra: 0.559 (+/-0.093)\n",
      ">1extra: 0.572 (+/-0.096)\n",
      ">2extra: 0.582 (+/-0.093)\n",
      ">3extra: 0.665 (+/-0.074)\n",
      ">0svml: 0.670 (+/-0.196)\n",
      ">1svml: 0.709 (+/-0.047)\n",
      ">2svml: 0.732 (+/-0.062)\n",
      ">3svml: 0.732 (+/-0.062)\n",
      ">0svmp: error\n",
      ">1svmp: 0.755 (+/-0.075)\n",
      ">2svmp: 0.667 (+/-0.023)\n",
      ">3svmp: 0.667 (+/-0.023)\n",
      ">0svmr0.1: 0.667 (+/-0.023)\n",
      ">1svmr0.1: 0.667 (+/-0.023)\n",
      ">2svmr0.1: 0.667 (+/-0.023)\n",
      ">3svmr0.1: 0.667 (+/-0.023)\n",
      ">0svmr0.2: 0.667 (+/-0.023)\n",
      ">1svmr0.2: 0.667 (+/-0.023)\n",
      ">2svmr0.2: 0.667 (+/-0.023)\n",
      ">3svmr0.2: 0.667 (+/-0.023)\n",
      ">0svmr0.3: 0.667 (+/-0.023)\n",
      ">1svmr0.3: 0.667 (+/-0.023)\n",
      ">2svmr0.3: 0.667 (+/-0.023)\n",
      ">3svmr0.3: 0.667 (+/-0.023)\n",
      ">0svmr0.4: 0.667 (+/-0.023)\n",
      ">1svmr0.4: 0.667 (+/-0.023)\n",
      ">2svmr0.4: 0.667 (+/-0.023)\n",
      ">3svmr0.4: 0.667 (+/-0.023)\n",
      ">0svmr0.5: 0.667 (+/-0.023)\n",
      ">1svmr0.5: 0.667 (+/-0.023)\n",
      ">2svmr0.5: 0.667 (+/-0.023)\n",
      ">3svmr0.5: 0.667 (+/-0.023)\n",
      ">0svmr0.6: 0.667 (+/-0.023)\n",
      ">1svmr0.6: 0.642 (+/-0.027)\n",
      ">2svmr0.6: 0.667 (+/-0.023)\n",
      ">3svmr0.6: 0.667 (+/-0.023)\n",
      ">0svmr0.7: 0.667 (+/-0.023)\n",
      ">1svmr0.7: 0.642 (+/-0.027)\n",
      ">2svmr0.7: 0.667 (+/-0.023)\n",
      ">3svmr0.7: 0.667 (+/-0.023)\n",
      ">0svmr0.8: 0.667 (+/-0.023)\n",
      ">1svmr0.8: 0.642 (+/-0.027)\n",
      ">2svmr0.8: 0.667 (+/-0.023)\n",
      ">3svmr0.8: 0.667 (+/-0.023)\n",
      ">0svmr0.9: 0.667 (+/-0.023)\n",
      ">1svmr0.9: 0.622 (+/-0.032)\n",
      ">2svmr0.9: 0.667 (+/-0.023)\n",
      ">3svmr0.9: 0.667 (+/-0.023)\n",
      ">0svmr1.0: 0.667 (+/-0.023)\n",
      ">1svmr1.0: 0.622 (+/-0.032)\n",
      ">2svmr1.0: 0.667 (+/-0.023)\n",
      ">3svmr1.0: 0.667 (+/-0.023)\n",
      ">0svmr2: 0.667 (+/-0.023)\n",
      ">1svmr2: 0.605 (+/-0.073)\n",
      ">2svmr2: 0.620 (+/-0.051)\n",
      ">3svmr2: 0.620 (+/-0.051)\n",
      ">0svmr3: 0.667 (+/-0.023)\n",
      ">1svmr3: 0.584 (+/-0.087)\n",
      ">2svmr3: 0.690 (+/-0.025)\n",
      ">3svmr3: 0.690 (+/-0.025)\n",
      ">0svmr4: 0.667 (+/-0.023)\n",
      ">1svmr4: 0.605 (+/-0.073)\n",
      ">2svmr4: 0.688 (+/-0.042)\n",
      ">3svmr4: 0.688 (+/-0.042)\n",
      ">0svmr5: 0.667 (+/-0.023)\n",
      ">1svmr5: 0.605 (+/-0.073)\n",
      ">2svmr5: 0.730 (+/-0.072)\n",
      ">3svmr5: 0.730 (+/-0.072)\n",
      ">0svmr6: 0.667 (+/-0.023)\n",
      ">1svmr6: 0.584 (+/-0.087)\n",
      ">2svmr6: 0.709 (+/-0.047)\n",
      ">3svmr6: 0.709 (+/-0.047)\n",
      ">0svmr7: 0.667 (+/-0.023)\n",
      ">1svmr7: 0.563 (+/-0.111)\n",
      ">2svmr7: 0.709 (+/-0.047)\n",
      ">3svmr7: 0.709 (+/-0.047)\n",
      ">0svmr8: 0.667 (+/-0.023)\n",
      ">1svmr8: 0.541 (+/-0.103)\n",
      ">2svmr8: 0.709 (+/-0.047)\n",
      ">3svmr8: 0.709 (+/-0.047)\n",
      ">0svmr9: 0.667 (+/-0.023)\n",
      ">1svmr9: 0.541 (+/-0.103)\n",
      ">2svmr9: 0.709 (+/-0.047)\n",
      ">3svmr9: 0.709 (+/-0.047)\n",
      ">0svmr10: 0.667 (+/-0.023)\n",
      ">1svmr10: 0.541 (+/-0.103)\n",
      ">2svmr10: 0.709 (+/-0.047)\n",
      ">3svmr10: 0.709 (+/-0.047)\n",
      ">0svmr20: 0.667 (+/-0.023)\n",
      ">1svmr20: 0.518 (+/-0.109)\n",
      ">2svmr20: 0.666 (+/-0.075)\n",
      ">3svmr20: 0.666 (+/-0.075)\n",
      ">0svmr30: 0.667 (+/-0.023)\n",
      ">1svmr30: 0.518 (+/-0.109)\n",
      ">2svmr30: 0.601 (+/-0.095)\n",
      ">3svmr30: 0.601 (+/-0.095)\n",
      ">0svmr40: 0.667 (+/-0.023)\n",
      ">1svmr40: 0.518 (+/-0.109)\n",
      ">2svmr40: 0.622 (+/-0.114)\n",
      ">3svmr40: 0.622 (+/-0.114)\n",
      ">0svmr50: 0.667 (+/-0.023)\n",
      ">1svmr50: 0.518 (+/-0.109)\n",
      ">2svmr50: 0.643 (+/-0.113)\n",
      ">3svmr50: 0.643 (+/-0.113)\n",
      ">0svmr60: 0.667 (+/-0.023)\n",
      ">1svmr60: 0.518 (+/-0.109)\n",
      ">2svmr60: 0.622 (+/-0.098)\n",
      ">3svmr60: 0.622 (+/-0.098)\n",
      ">0svmr70: 0.667 (+/-0.023)\n",
      ">1svmr70: 0.518 (+/-0.109)\n",
      ">2svmr70: 0.622 (+/-0.098)\n",
      ">3svmr70: 0.622 (+/-0.098)\n",
      ">0svmr80: 0.667 (+/-0.023)\n",
      ">1svmr80: 0.518 (+/-0.109)\n",
      ">2svmr80: 0.622 (+/-0.098)\n",
      ">3svmr80: 0.622 (+/-0.098)\n",
      ">0svmr90: 0.667 (+/-0.023)\n",
      ">1svmr90: 0.518 (+/-0.109)\n",
      ">2svmr90: 0.622 (+/-0.098)\n",
      ">3svmr90: 0.622 (+/-0.098)\n",
      ">0svmr100: 0.667 (+/-0.023)\n",
      ">1svmr100: 0.518 (+/-0.109)\n",
      ">2svmr100: 0.601 (+/-0.095)\n",
      ">3svmr100: 0.601 (+/-0.095)\n",
      ">0bayes: 0.647 (+/-0.043)\n",
      ">1bayes: 0.647 (+/-0.094)\n",
      ">2bayes: 0.647 (+/-0.094)\n",
      ">3bayes: 0.647 (+/-0.094)\n",
      ">0ada: 0.509 (+/-0.084)\n",
      ">1ada: 0.513 (+/-0.079)\n",
      ">2ada: 0.509 (+/-0.084)\n",
      ">3ada: 0.534 (+/-0.059)\n",
      ">0bag: 0.555 (+/-0.132)\n",
      ">1bag: 0.514 (+/-0.079)\n",
      ">2bag: 0.536 (+/-0.072)\n",
      ">3bag: 0.576 (+/-0.113)\n",
      ">0rf: 0.597 (+/-0.105)\n",
      ">1rf: 0.576 (+/-0.077)\n",
      ">2rf: 0.576 (+/-0.077)\n",
      ">3rf: 0.576 (+/-0.077)\n",
      ">0et: 0.647 (+/-0.043)\n",
      ">1et: 0.603 (+/-0.058)\n",
      ">2et: 0.603 (+/-0.058)\n",
      ">3et: 0.624 (+/-0.062)\n",
      ">0gbm: 0.536 (+/-0.072)\n",
      ">1gbm: 0.557 (+/-0.038)\n",
      ">2gbm: 0.557 (+/-0.038)\n",
      ">3gbm: 0.557 (+/-0.038)\n",
      "\n",
      "Rank=1, Name=1svmp, Score=0.755 (+/- 0.075)\n",
      "Rank=2, Name=1ridge-1.0, Score=0.755 (+/- 0.042)\n",
      "Rank=3, Name=0ridge-1.0, Score=0.755 (+/- 0.042)\n",
      "Rank=4, Name=1ridge-0.9, Score=0.755 (+/- 0.042)\n",
      "Rank=5, Name=0ridge-0.9, Score=0.755 (+/- 0.042)\n",
      "Rank=6, Name=1ridge-0.8, Score=0.755 (+/- 0.042)\n",
      "Rank=7, Name=0ridge-0.8, Score=0.755 (+/- 0.042)\n",
      "Rank=8, Name=1ridge-0.7, Score=0.755 (+/- 0.042)\n",
      "Rank=9, Name=0ridge-0.7, Score=0.755 (+/- 0.042)\n",
      "Rank=10, Name=1ridge-0.6, Score=0.755 (+/- 0.042)\n",
      "Rank=11, Name=0ridge-0.6, Score=0.755 (+/- 0.042)\n",
      "Rank=12, Name=1ridge-0.5, Score=0.755 (+/- 0.042)\n",
      "Rank=13, Name=0ridge-0.5, Score=0.755 (+/- 0.042)\n",
      "Rank=14, Name=1ridge-0.4, Score=0.755 (+/- 0.042)\n",
      "Rank=15, Name=0ridge-0.4, Score=0.755 (+/- 0.042)\n",
      "Rank=16, Name=1ridge-0.3, Score=0.755 (+/- 0.042)\n",
      "Rank=17, Name=0ridge-0.3, Score=0.755 (+/- 0.042)\n",
      "Rank=18, Name=1ridge-0.2, Score=0.755 (+/- 0.042)\n",
      "Rank=19, Name=0ridge-0.2, Score=0.755 (+/- 0.042)\n",
      "Rank=20, Name=3ridge-0.1, Score=0.755 (+/- 0.042)\n"
     ]
    }
   ],
   "source": [
    "# binary classification spot check script\n",
    "import warnings\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    " \n",
    " \n",
    " # create a dict of standard models to evaluate {name:object}\n",
    "def define_models(models=dict()):\n",
    "\t# linear models\n",
    "\tmodels['logistic'] = LogisticRegression()\n",
    "\talpha = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\tfor a in alpha:\n",
    "\t\tmodels['ridge-'+str(a)] = RidgeClassifier(alpha=a)\n",
    "\tmodels['sgd'] = SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "\tmodels['pa'] = PassiveAggressiveClassifier(max_iter=1000, tol=1e-3)\n",
    "\t# non-linear models\n",
    "\tn_neighbors = range(1, 10)\n",
    "\tfor k in n_neighbors:\n",
    "\t\tmodels['knn-'+str(k)] = KNeighborsClassifier(n_neighbors=k)\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['extra'] = ExtraTreeClassifier()\n",
    "\tmodels['svml'] = SVC(kernel='linear')\n",
    "\tmodels['svmp'] = SVC(kernel='poly')\n",
    "\tc_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2,3,4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100]\n",
    "\tfor c in c_values:\n",
    "\t\tmodels['svmr'+str(c)] = SVC(C=c)\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\t# ensemble models\n",
    "\tn_trees = 100\n",
    "\tmodels['ada'] = AdaBoostClassifier(n_estimators=n_trees)\n",
    "\tmodels['bag'] = BaggingClassifier(n_estimators=n_trees)\n",
    "\tmodels['rf'] = RandomForestClassifier(n_estimators=n_trees)\n",
    "\tmodels['et'] = ExtraTreesClassifier(n_estimators=n_trees)\n",
    "\tmodels['gbm'] = GradientBoostingClassifier(n_estimators=n_trees)\n",
    "\tprint('Defined %d models' % len(models))\n",
    "\treturn models\n",
    " \n",
    "# no transforms pipeline\n",
    "def pipeline_none(model):\n",
    "\treturn model\n",
    " \n",
    "# standardize transform pipeline\n",
    "def pipeline_standardize(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    " \n",
    "# normalize transform pipeline\n",
    "def pipeline_normalize(model):\n",
    "\tsteps = list()\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    " \n",
    "# standardize and normalize pipeline\n",
    "def pipeline_std_norm(model):\n",
    "\tsteps = list()\n",
    "\t# standardization\n",
    "\tsteps.append(('standardize', StandardScaler()))\n",
    "\t# normalization\n",
    "\tsteps.append(('normalize', MinMaxScaler()))\n",
    "\t# the model\n",
    "\tsteps.append(('model', model))\n",
    "\t# create pipeline\n",
    "\tpipeline = Pipeline(steps=steps)\n",
    "\treturn pipeline\n",
    " \n",
    "# evaluate a single model\n",
    "def evaluate_model(X_train, Y_train, model, folds, metric, pipe_func):\n",
    "\t# create the pipeline\n",
    "\tpipeline = pipe_func(model)\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(pipeline, X_train, Y_train, scoring=metric, cv=folds, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# evaluate a model and try to trap errors and and hide warnings\n",
    "def robust_evaluate_model(X_train, Y_train, model, folds, metric, pipe_func):\n",
    "\tscores = None\n",
    "\ttry:\n",
    "\t\twith warnings.catch_warnings():\n",
    "\t\t\twarnings.filterwarnings(\"ignore\")\n",
    "\t\t\tscores = evaluate_model(X_train, Y_train, model, folds, metric, pipe_func)\n",
    "\texcept:\n",
    "\t\tscores = None\n",
    "\treturn scores\n",
    " \n",
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X_train, Y_train, models, pipe_funcs, folds=4, metric='accuracy'):\n",
    "\tresults = dict()\n",
    "\tfor name, model in models.items():\n",
    "\t\t# evaluate model under each preparation function\n",
    "\t\tfor i in range(len(pipe_funcs)):\n",
    "\t\t\t# evaluate the model\n",
    "\t\t\tscores = robust_evaluate_model(X_train, Y_train, model, folds, metric, pipe_funcs[i])\n",
    "\t\t\t# update name\n",
    "\t\t\trun_name = str(i) + name\n",
    "\t\t\t# show process\n",
    "\t\t\tif scores is not None:\n",
    "\t\t\t\t# store a result\n",
    "\t\t\t\tresults[run_name] = scores\n",
    "\t\t\t\tmean_score, std_score = mean(scores), std(scores)\n",
    "\t\t\t\tprint('>%s: %.3f (+/-%.3f)' % (run_name, mean_score, std_score))\n",
    "\t\t\telse:\n",
    "\t\t\t\tprint('>%s: error' % run_name)\n",
    "\treturn results\n",
    " \n",
    "# print and plot the top n results\n",
    "def summarize_results(results, maximize=True, top_n=20):\n",
    "\t# check for no results\n",
    "\tif len(results) == 0:\n",
    "\t\tprint('no results')\n",
    "\t\treturn\n",
    "\t# determine how many results to summarize\n",
    "\tn = min(top_n, len(results))\n",
    "\t# create a list of (name, mean(scores)) tuples\n",
    "\tmean_scores = [(k,mean(v)) for k,v in results.items()]\n",
    "\t# sort tuples by mean score\n",
    "\tmean_scores = sorted(mean_scores, key=lambda x: x[1])\n",
    "\t# reverse for descending order (e.g. for accuracy)\n",
    "\tif maximize:\n",
    "\t\tmean_scores = list(reversed(mean_scores))\n",
    "\t# retrieve the top n for summarization\n",
    "\tnames = [x[0] for x in mean_scores[:n]]\n",
    "\tscores = [results[x[0]] for x in mean_scores[:n]]\n",
    "\t# print the top n\n",
    "\tprint()\n",
    "\tfor i in range(n):\n",
    "\t\tname = names[i]\n",
    "\t\tmean_score, std_score = mean(results[name]), std(results[name])\n",
    "\t\tprint('Rank=%d, Name=%s, Score=%.3f (+/- %.3f)' % (i+1, name, mean_score, std_score))\n",
    "\t# boxplot for the top n\n",
    "\tpyplot.boxplot(scores, labels=names)\n",
    "\t_, labels = pyplot.xticks()\n",
    "\tpyplot.setp(labels, rotation=90)\n",
    "\tpyplot.savefig('spotcheck.png')\n",
    " \n",
    "\n",
    "# get model list\n",
    "models = define_models()\n",
    "# define transform pipelines\n",
    "pipelines = [pipeline_none, pipeline_standardize, pipeline_normalize, pipeline_std_norm]\n",
    "# evaluate models\n",
    "results = evaluate_models(X_train, Y_train, models, pipelines)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import files below:\n",
    "\n",
    "1. data1 = stepcount + demographic data in discrete categories\n",
    "2. d1 = demographic data in discrete categories\n",
    "3. data2 = stepcount + demographic data as continuous variables\n",
    "4. d2 = demographic data as a continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'no_band_steps.xlsx'\n",
    "data1 = pd.read_excel(file1)\n",
    "data1 = data1.set_index('studyID')\n",
    "\n",
    "d1 = data1.drop(columns = 'Steps')\n",
    "\n",
    "file2 = 'band_steps.xlsx'\n",
    "data2 = pd.read_excel(file2)\n",
    "data2 = data2.set_index('studyID')\n",
    "\n",
    "d2 = data2.drop(columns = 'Steps_band')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographic: No Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  122\n",
      "Training Accuracy: 0.7111111111111111\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  200\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.3333333333333333\n",
      "Random State:  300\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.75\n",
      "Random State:  368\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.5\n",
      "Random State:  400\n",
      "Training Accuracy: 0.7333333333333333\n",
      "Test Accuracy: 0.5\n",
      "Random State:  500\n",
      "Training Accuracy: 0.7555555555555555\n",
      "Test Accuracy: 0.5\n",
      "Random State:  600\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.75\n",
      "Random State:  700\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  22\n",
      "Training Accuracy: 0.7333333333333333\n",
      "Test Accuracy: 0.75\n",
      "Mean Training Accuracy: 0.7666666666666666\n",
      "Mean Test Accuracy: 0.5916666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "d1_train_acc = []\n",
    "d1_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(d1, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    d1_train_acc.append(svm_train_acc)\n",
    "    d1_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(d1_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(d1_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demographic: Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  122\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.75\n",
      "Random State:  200\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  300\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  368\n",
      "Training Accuracy: 0.7555555555555555\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  400\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  500\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.5\n",
      "Random State:  600\n",
      "Training Accuracy: 0.7555555555555555\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  700\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  22\n",
      "Training Accuracy: 0.7555555555555555\n",
      "Test Accuracy: 0.75\n",
      "Mean Training Accuracy: 0.7977777777777778\n",
      "Mean Test Accuracy: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "d2_train_acc = []\n",
    "d2_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(d2, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    d2_train_acc.append(svm_train_acc)\n",
    "    d2_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(d2_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(d2_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps + Demographic: No Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.6666666666666666\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  122\n",
      "Training Accuracy: 0.6444444444444445\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  200\n",
      "Training Accuracy: 0.6222222222222222\n",
      "Test Accuracy: 0.5\n",
      "Random State:  300\n",
      "Training Accuracy: 0.7333333333333333\n",
      "Test Accuracy: 0.5\n",
      "Random State:  368\n",
      "Training Accuracy: 0.6888888888888889\n",
      "Test Accuracy: 0.4166666666666667\n",
      "Random State:  400\n",
      "Training Accuracy: 0.5555555555555556\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  500\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  600\n",
      "Training Accuracy: 0.7111111111111111\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  700\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  22\n",
      "Training Accuracy: 0.5777777777777777\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Mean Training Accuracy: 0.6755555555555556\n",
      "Mean Test Accuracy: 0.5916666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "data1_train_acc = []\n",
    "data1_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(data1, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    data1_train_acc.append(svm_train_acc)\n",
    "    data1_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(data1_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(data1_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps + Demographic: Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.75\n",
      "Random State:  122\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.75\n",
      "Random State:  200\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  300\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.75\n",
      "Random State:  368\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.5\n",
      "Random State:  400\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  500\n",
      "Training Accuracy: 0.8666666666666667\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  600\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.75\n",
      "Random State:  700\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  22\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.9166666666666666\n",
      "Mean Training Accuracy: 0.8155555555555555\n",
      "Mean Test Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "data2_train_acc = []\n",
    "data2_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(data2, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    data2_train_acc.append(svm_train_acc)\n",
    "    data2_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(data2_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(data2_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important files below:\n",
    "\n",
    "1. no_band_final = KEGG + Demographic + stepcount data as continuous variables\n",
    "2. norm_no_band_final = KEGG + Demographic + stepcount data as continuous variables\n",
    "3. band_final = KEGG + Demographic + stepcount data as discrete variables\n",
    "4. norm_band_final = KEGG + Demographic + stepcount data as discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_band_final = pd.read_excel('final_no_band.xlsx')\n",
    "no_band_final = no_band_final.set_index('studyID')\n",
    "\n",
    "norm_no_band_final = pd.read_excel('norm_final_no_band.xlsx')\n",
    "norm_no_band_final = norm_no_band_final.set_index('studyID')\n",
    "\n",
    "band_final = pd.read_excel('final_band.xlsx')\n",
    "band_final = band_final.set_index('studyID')\n",
    "\n",
    "norm_band_final = pd.read_excel('norm_final_band.xlsx')\n",
    "norm_band_final = norm_band_final.set_index('studyID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEGG + Demographic: No Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.75\n",
      "Random State:  122\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.9166666666666666\n",
      "Random State:  200\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.75\n",
      "Random State:  300\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.75\n",
      "Random State:  368\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.4166666666666667\n",
      "Random State:  400\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.75\n",
      "Random State:  500\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  600\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  700\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.9166666666666666\n",
      "Random State:  22\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.75\n",
      "Mean Training Accuracy: 1.0\n",
      "Mean Test Accuracy: 0.7250000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "no_band_train_acc = []\n",
    "no_band_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(no_band_final, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    no_band_train_acc.append(svm_train_acc)\n",
    "    no_band_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(no_band_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(no_band_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEGG + Demographic: No Band,\n",
    "Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.75\n",
      "Test Accuracy: 0.5\n",
      "Random State:  122\n",
      "Training Accuracy: 0.7727272727272727\n",
      "Test Accuracy: 0.75\n",
      "Random State:  200\n",
      "Training Accuracy: 0.8409090909090909\n",
      "Test Accuracy: 0.5\n",
      "Random State:  300\n",
      "Training Accuracy: 0.7045454545454546\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  368\n",
      "Training Accuracy: 0.7727272727272727\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  400\n",
      "Training Accuracy: 0.75\n",
      "Test Accuracy: 0.5\n",
      "Random State:  500\n",
      "Training Accuracy: 0.8181818181818182\n",
      "Test Accuracy: 0.4166666666666667\n",
      "Random State:  600\n",
      "Training Accuracy: 0.7954545454545454\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  700\n",
      "Training Accuracy: 0.7727272727272727\n",
      "Test Accuracy: 0.75\n",
      "Random State:  22\n",
      "Training Accuracy: 0.6363636363636364\n",
      "Test Accuracy: 0.75\n",
      "Mean Training Accuracy: 0.7613636363636365\n",
      "Mean Test Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "norm_no_band_train_acc = []\n",
    "norm_no_band_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(norm_no_band_final, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    norm_no_band_train_acc.append(svm_train_acc)\n",
    "    norm_no_band_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(norm_no_band_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(norm_no_band_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEGG + Demographic: Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  122\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  200\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  300\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  368\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  400\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  500\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  600\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  700\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  22\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Mean Training Accuracy: 1.0\n",
      "Mean Test Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "band_train_acc = []\n",
    "band_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(band_final, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    band_train_acc.append(svm_train_acc)\n",
    "    band_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(band_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(band_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KEGG + Demographic: Band, \n",
    "Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.75\n",
      "Test Accuracy: 0.5\n",
      "Random State:  122\n",
      "Training Accuracy: 0.7954545454545454\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  200\n",
      "Training Accuracy: 0.8181818181818182\n",
      "Test Accuracy: 0.5\n",
      "Random State:  300\n",
      "Training Accuracy: 0.7045454545454546\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  368\n",
      "Training Accuracy: 0.7272727272727273\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  400\n",
      "Training Accuracy: 0.8181818181818182\n",
      "Test Accuracy: 0.5\n",
      "Random State:  500\n",
      "Training Accuracy: 0.8181818181818182\n",
      "Test Accuracy: 0.5\n",
      "Random State:  600\n",
      "Training Accuracy: 0.7954545454545454\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  700\n",
      "Training Accuracy: 0.7727272727272727\n",
      "Test Accuracy: 0.75\n",
      "Random State:  22\n",
      "Training Accuracy: 0.6363636363636364\n",
      "Test Accuracy: 0.75\n",
      "Mean Training Accuracy: 0.7636363636363637\n",
      "Mean Test Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "norm_band_train_acc = []\n",
    "norm_band_test_acc = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(norm_band_final, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    norm_band_train_acc.append(svm_train_acc)\n",
    "    norm_band_test_acc.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(norm_band_train_acc)) \n",
    "print('Mean Test Accuracy:', mean(norm_band_test_acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import PCA dataset and retain only first 6 PC's which account for 80% variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA = pd.read_csv('PCA_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA.index = data1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studyID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>-469.941805</td>\n",
       "      <td>0.049335</td>\n",
       "      <td>0.010597</td>\n",
       "      <td>-0.025762</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>-0.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>8.061646</td>\n",
       "      <td>-5.761836</td>\n",
       "      <td>-4.841193</td>\n",
       "      <td>-2.171323</td>\n",
       "      <td>-2.788218</td>\n",
       "      <td>2.032909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>8.430937</td>\n",
       "      <td>6.946562</td>\n",
       "      <td>1.794457</td>\n",
       "      <td>-0.015105</td>\n",
       "      <td>-3.024961</td>\n",
       "      <td>-0.200291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>8.256683</td>\n",
       "      <td>8.288072</td>\n",
       "      <td>2.570019</td>\n",
       "      <td>-0.302641</td>\n",
       "      <td>-3.554665</td>\n",
       "      <td>4.007124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>8.376866</td>\n",
       "      <td>-0.916554</td>\n",
       "      <td>-6.212482</td>\n",
       "      <td>1.182002</td>\n",
       "      <td>-0.328640</td>\n",
       "      <td>-1.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>8.258802</td>\n",
       "      <td>0.870977</td>\n",
       "      <td>4.219331</td>\n",
       "      <td>0.654543</td>\n",
       "      <td>-3.580225</td>\n",
       "      <td>1.235964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>8.150815</td>\n",
       "      <td>-2.103172</td>\n",
       "      <td>-4.738280</td>\n",
       "      <td>5.019986</td>\n",
       "      <td>1.739006</td>\n",
       "      <td>-0.470654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>8.529156</td>\n",
       "      <td>-1.075416</td>\n",
       "      <td>1.555243</td>\n",
       "      <td>0.975567</td>\n",
       "      <td>2.216324</td>\n",
       "      <td>-2.077344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>8.691007</td>\n",
       "      <td>1.723237</td>\n",
       "      <td>-5.095740</td>\n",
       "      <td>-5.872935</td>\n",
       "      <td>1.253795</td>\n",
       "      <td>5.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>8.330590</td>\n",
       "      <td>-3.492446</td>\n",
       "      <td>-2.573330</td>\n",
       "      <td>-3.440519</td>\n",
       "      <td>0.589523</td>\n",
       "      <td>-0.811196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>8.553131</td>\n",
       "      <td>1.277476</td>\n",
       "      <td>-1.114016</td>\n",
       "      <td>-5.234553</td>\n",
       "      <td>-3.206028</td>\n",
       "      <td>-1.501332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>8.672488</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>-4.417824</td>\n",
       "      <td>-4.974068</td>\n",
       "      <td>5.015134</td>\n",
       "      <td>1.444570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>8.060924</td>\n",
       "      <td>-3.404177</td>\n",
       "      <td>-1.670905</td>\n",
       "      <td>-0.015766</td>\n",
       "      <td>-0.589810</td>\n",
       "      <td>0.814938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>8.407316</td>\n",
       "      <td>2.780576</td>\n",
       "      <td>1.494663</td>\n",
       "      <td>2.738389</td>\n",
       "      <td>-0.350899</td>\n",
       "      <td>0.061606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>8.343725</td>\n",
       "      <td>-6.346800</td>\n",
       "      <td>1.870356</td>\n",
       "      <td>-2.797520</td>\n",
       "      <td>0.811928</td>\n",
       "      <td>3.526702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>8.147480</td>\n",
       "      <td>-2.233272</td>\n",
       "      <td>0.046852</td>\n",
       "      <td>2.516327</td>\n",
       "      <td>-6.168731</td>\n",
       "      <td>1.153224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>8.245402</td>\n",
       "      <td>2.583637</td>\n",
       "      <td>-5.067404</td>\n",
       "      <td>1.450122</td>\n",
       "      <td>-1.004123</td>\n",
       "      <td>-0.366070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2027</th>\n",
       "      <td>8.418932</td>\n",
       "      <td>-1.388080</td>\n",
       "      <td>0.822838</td>\n",
       "      <td>2.751003</td>\n",
       "      <td>0.937574</td>\n",
       "      <td>1.443123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>8.491096</td>\n",
       "      <td>-1.872720</td>\n",
       "      <td>-0.678135</td>\n",
       "      <td>-0.711563</td>\n",
       "      <td>-0.222693</td>\n",
       "      <td>-0.312042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>8.264237</td>\n",
       "      <td>7.226015</td>\n",
       "      <td>-4.778999</td>\n",
       "      <td>2.936601</td>\n",
       "      <td>0.712041</td>\n",
       "      <td>1.266246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>8.672182</td>\n",
       "      <td>1.537966</td>\n",
       "      <td>-2.587992</td>\n",
       "      <td>-3.731065</td>\n",
       "      <td>2.494876</td>\n",
       "      <td>-3.342242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>8.355781</td>\n",
       "      <td>-2.301926</td>\n",
       "      <td>-2.285624</td>\n",
       "      <td>0.911886</td>\n",
       "      <td>-1.132307</td>\n",
       "      <td>-0.483702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>8.368244</td>\n",
       "      <td>-3.130138</td>\n",
       "      <td>0.359927</td>\n",
       "      <td>0.593016</td>\n",
       "      <td>-1.534503</td>\n",
       "      <td>-1.022820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>8.590522</td>\n",
       "      <td>2.825516</td>\n",
       "      <td>1.703487</td>\n",
       "      <td>-2.263489</td>\n",
       "      <td>-0.177073</td>\n",
       "      <td>-0.566768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>8.538296</td>\n",
       "      <td>3.298215</td>\n",
       "      <td>-0.561589</td>\n",
       "      <td>1.423183</td>\n",
       "      <td>-1.070922</td>\n",
       "      <td>-0.696679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>8.201924</td>\n",
       "      <td>-3.816921</td>\n",
       "      <td>0.290515</td>\n",
       "      <td>-0.127418</td>\n",
       "      <td>-3.355348</td>\n",
       "      <td>-0.349419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2041</th>\n",
       "      <td>8.643114</td>\n",
       "      <td>3.246810</td>\n",
       "      <td>0.764220</td>\n",
       "      <td>0.408927</td>\n",
       "      <td>3.508107</td>\n",
       "      <td>-2.106101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>8.371865</td>\n",
       "      <td>-1.981267</td>\n",
       "      <td>-1.563791</td>\n",
       "      <td>-0.540715</td>\n",
       "      <td>-0.513858</td>\n",
       "      <td>-2.490245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2044</th>\n",
       "      <td>8.535858</td>\n",
       "      <td>3.013037</td>\n",
       "      <td>-0.605939</td>\n",
       "      <td>-0.291089</td>\n",
       "      <td>-0.372845</td>\n",
       "      <td>-1.107763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>8.599565</td>\n",
       "      <td>0.546161</td>\n",
       "      <td>1.997073</td>\n",
       "      <td>-3.759542</td>\n",
       "      <td>1.380745</td>\n",
       "      <td>-2.453152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>8.039447</td>\n",
       "      <td>-2.255299</td>\n",
       "      <td>-7.415057</td>\n",
       "      <td>3.669246</td>\n",
       "      <td>-1.180383</td>\n",
       "      <td>0.393992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>8.484428</td>\n",
       "      <td>12.066927</td>\n",
       "      <td>-1.882757</td>\n",
       "      <td>1.686828</td>\n",
       "      <td>-0.545354</td>\n",
       "      <td>0.710268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>8.432169</td>\n",
       "      <td>2.671558</td>\n",
       "      <td>0.831073</td>\n",
       "      <td>-0.666775</td>\n",
       "      <td>-0.742707</td>\n",
       "      <td>-1.167079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>8.323865</td>\n",
       "      <td>-2.300951</td>\n",
       "      <td>3.300956</td>\n",
       "      <td>-3.542203</td>\n",
       "      <td>-1.225608</td>\n",
       "      <td>-1.749491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>8.444841</td>\n",
       "      <td>-2.191852</td>\n",
       "      <td>-1.072098</td>\n",
       "      <td>0.263681</td>\n",
       "      <td>1.438553</td>\n",
       "      <td>-0.265604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>8.629302</td>\n",
       "      <td>3.695414</td>\n",
       "      <td>1.962989</td>\n",
       "      <td>-0.168602</td>\n",
       "      <td>3.104051</td>\n",
       "      <td>-1.800245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>8.264779</td>\n",
       "      <td>-3.280402</td>\n",
       "      <td>1.015337</td>\n",
       "      <td>-1.321412</td>\n",
       "      <td>0.364280</td>\n",
       "      <td>3.986855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>8.254871</td>\n",
       "      <td>-3.873659</td>\n",
       "      <td>2.332344</td>\n",
       "      <td>2.706155</td>\n",
       "      <td>1.017899</td>\n",
       "      <td>1.518916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>8.225923</td>\n",
       "      <td>-4.379280</td>\n",
       "      <td>5.395098</td>\n",
       "      <td>0.643380</td>\n",
       "      <td>-0.522846</td>\n",
       "      <td>1.641336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>8.576496</td>\n",
       "      <td>1.825386</td>\n",
       "      <td>1.830427</td>\n",
       "      <td>1.736049</td>\n",
       "      <td>1.083117</td>\n",
       "      <td>1.329922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>8.504692</td>\n",
       "      <td>2.869858</td>\n",
       "      <td>2.486749</td>\n",
       "      <td>0.181788</td>\n",
       "      <td>0.109939</td>\n",
       "      <td>-1.018897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>8.488433</td>\n",
       "      <td>2.691665</td>\n",
       "      <td>2.489616</td>\n",
       "      <td>-3.797473</td>\n",
       "      <td>-0.882744</td>\n",
       "      <td>-1.749357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>8.166598</td>\n",
       "      <td>-4.312415</td>\n",
       "      <td>-0.270006</td>\n",
       "      <td>-1.150707</td>\n",
       "      <td>-3.534556</td>\n",
       "      <td>-1.603007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>8.471067</td>\n",
       "      <td>-2.033303</td>\n",
       "      <td>2.538065</td>\n",
       "      <td>-0.638137</td>\n",
       "      <td>-0.642090</td>\n",
       "      <td>-1.409690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2069</th>\n",
       "      <td>8.475878</td>\n",
       "      <td>2.034554</td>\n",
       "      <td>2.083044</td>\n",
       "      <td>0.841771</td>\n",
       "      <td>0.344256</td>\n",
       "      <td>-0.219077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070</th>\n",
       "      <td>7.730424</td>\n",
       "      <td>-10.018744</td>\n",
       "      <td>0.240801</td>\n",
       "      <td>6.367664</td>\n",
       "      <td>1.711156</td>\n",
       "      <td>-0.850079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>8.601290</td>\n",
       "      <td>3.542187</td>\n",
       "      <td>4.452587</td>\n",
       "      <td>2.890032</td>\n",
       "      <td>1.828924</td>\n",
       "      <td>0.131485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2072</th>\n",
       "      <td>8.560893</td>\n",
       "      <td>-1.594250</td>\n",
       "      <td>-1.647282</td>\n",
       "      <td>-2.723124</td>\n",
       "      <td>0.224553</td>\n",
       "      <td>-1.012382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>8.197183</td>\n",
       "      <td>1.335963</td>\n",
       "      <td>-3.625672</td>\n",
       "      <td>3.435099</td>\n",
       "      <td>-0.507488</td>\n",
       "      <td>-1.914244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>8.585552</td>\n",
       "      <td>4.997746</td>\n",
       "      <td>2.660706</td>\n",
       "      <td>1.716662</td>\n",
       "      <td>0.896149</td>\n",
       "      <td>-0.516922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>8.582159</td>\n",
       "      <td>2.156954</td>\n",
       "      <td>-0.604313</td>\n",
       "      <td>-0.555713</td>\n",
       "      <td>2.828488</td>\n",
       "      <td>2.684208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2080</th>\n",
       "      <td>8.157351</td>\n",
       "      <td>-5.496158</td>\n",
       "      <td>3.759084</td>\n",
       "      <td>-0.302786</td>\n",
       "      <td>0.009967</td>\n",
       "      <td>-0.435177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>8.340156</td>\n",
       "      <td>-5.443016</td>\n",
       "      <td>3.750250</td>\n",
       "      <td>-0.556543</td>\n",
       "      <td>2.521893</td>\n",
       "      <td>0.852497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>8.602448</td>\n",
       "      <td>3.699124</td>\n",
       "      <td>1.790843</td>\n",
       "      <td>0.229875</td>\n",
       "      <td>0.397740</td>\n",
       "      <td>1.201343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2083</th>\n",
       "      <td>8.504195</td>\n",
       "      <td>-1.378563</td>\n",
       "      <td>2.362360</td>\n",
       "      <td>2.122315</td>\n",
       "      <td>3.813338</td>\n",
       "      <td>1.492260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2084</th>\n",
       "      <td>8.311902</td>\n",
       "      <td>-1.916312</td>\n",
       "      <td>0.251801</td>\n",
       "      <td>-0.553506</td>\n",
       "      <td>-1.146012</td>\n",
       "      <td>-1.740736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>8.416877</td>\n",
       "      <td>0.482019</td>\n",
       "      <td>0.276718</td>\n",
       "      <td>0.199955</td>\n",
       "      <td>1.532236</td>\n",
       "      <td>1.047101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PC1        PC2       PC3       PC4       PC5       PC6\n",
       "studyID                                                               \n",
       "2001    -469.941805   0.049335  0.010597 -0.025762  0.020042 -0.004671\n",
       "2002       8.061646  -5.761836 -4.841193 -2.171323 -2.788218  2.032909\n",
       "2003       8.430937   6.946562  1.794457 -0.015105 -3.024961 -0.200291\n",
       "2004       8.256683   8.288072  2.570019 -0.302641 -3.554665  4.007124\n",
       "2006       8.376866  -0.916554 -6.212482  1.182002 -0.328640 -1.162400\n",
       "2008       8.258802   0.870977  4.219331  0.654543 -3.580225  1.235964\n",
       "2010       8.150815  -2.103172 -4.738280  5.019986  1.739006 -0.470654\n",
       "2012       8.529156  -1.075416  1.555243  0.975567  2.216324 -2.077344\n",
       "2013       8.691007   1.723237 -5.095740 -5.872935  1.253795  5.000286\n",
       "2014       8.330590  -3.492446 -2.573330 -3.440519  0.589523 -0.811196\n",
       "2017       8.553131   1.277476 -1.114016 -5.234553 -3.206028 -1.501332\n",
       "2021       8.672488   0.015981 -4.417824 -4.974068  5.015134  1.444570\n",
       "2022       8.060924  -3.404177 -1.670905 -0.015766 -0.589810  0.814938\n",
       "2023       8.407316   2.780576  1.494663  2.738389 -0.350899  0.061606\n",
       "2024       8.343725  -6.346800  1.870356 -2.797520  0.811928  3.526702\n",
       "2025       8.147480  -2.233272  0.046852  2.516327 -6.168731  1.153224\n",
       "2026       8.245402   2.583637 -5.067404  1.450122 -1.004123 -0.366070\n",
       "2027       8.418932  -1.388080  0.822838  2.751003  0.937574  1.443123\n",
       "2028       8.491096  -1.872720 -0.678135 -0.711563 -0.222693 -0.312042\n",
       "2029       8.264237   7.226015 -4.778999  2.936601  0.712041  1.266246\n",
       "2031       8.672182   1.537966 -2.587992 -3.731065  2.494876 -3.342242\n",
       "2032       8.355781  -2.301926 -2.285624  0.911886 -1.132307 -0.483702\n",
       "2033       8.368244  -3.130138  0.359927  0.593016 -1.534503 -1.022820\n",
       "2035       8.590522   2.825516  1.703487 -2.263489 -0.177073 -0.566768\n",
       "2037       8.538296   3.298215 -0.561589  1.423183 -1.070922 -0.696679\n",
       "2039       8.201924  -3.816921  0.290515 -0.127418 -3.355348 -0.349419\n",
       "2041       8.643114   3.246810  0.764220  0.408927  3.508107 -2.106101\n",
       "2043       8.371865  -1.981267 -1.563791 -0.540715 -0.513858 -2.490245\n",
       "2044       8.535858   3.013037 -0.605939 -0.291089 -0.372845 -1.107763\n",
       "2045       8.599565   0.546161  1.997073 -3.759542  1.380745 -2.453152\n",
       "2046       8.039447  -2.255299 -7.415057  3.669246 -1.180383  0.393992\n",
       "2047       8.484428  12.066927 -1.882757  1.686828 -0.545354  0.710268\n",
       "2048       8.432169   2.671558  0.831073 -0.666775 -0.742707 -1.167079\n",
       "2050       8.323865  -2.300951  3.300956 -3.542203 -1.225608 -1.749491\n",
       "2054       8.444841  -2.191852 -1.072098  0.263681  1.438553 -0.265604\n",
       "2055       8.629302   3.695414  1.962989 -0.168602  3.104051 -1.800245\n",
       "2056       8.264779  -3.280402  1.015337 -1.321412  0.364280  3.986855\n",
       "2057       8.254871  -3.873659  2.332344  2.706155  1.017899  1.518916\n",
       "2058       8.225923  -4.379280  5.395098  0.643380 -0.522846  1.641336\n",
       "2059       8.576496   1.825386  1.830427  1.736049  1.083117  1.329922\n",
       "2060       8.504692   2.869858  2.486749  0.181788  0.109939 -1.018897\n",
       "2063       8.488433   2.691665  2.489616 -3.797473 -0.882744 -1.749357\n",
       "2066       8.166598  -4.312415 -0.270006 -1.150707 -3.534556 -1.603007\n",
       "2067       8.471067  -2.033303  2.538065 -0.638137 -0.642090 -1.409690\n",
       "2069       8.475878   2.034554  2.083044  0.841771  0.344256 -0.219077\n",
       "2070       7.730424 -10.018744  0.240801  6.367664  1.711156 -0.850079\n",
       "2071       8.601290   3.542187  4.452587  2.890032  1.828924  0.131485\n",
       "2072       8.560893  -1.594250 -1.647282 -2.723124  0.224553 -1.012382\n",
       "2074       8.197183   1.335963 -3.625672  3.435099 -0.507488 -1.914244\n",
       "2075       8.585552   4.997746  2.660706  1.716662  0.896149 -0.516922\n",
       "2078       8.582159   2.156954 -0.604313 -0.555713  2.828488  2.684208\n",
       "2080       8.157351  -5.496158  3.759084 -0.302786  0.009967 -0.435177\n",
       "2081       8.340156  -5.443016  3.750250 -0.556543  2.521893  0.852497\n",
       "2082       8.602448   3.699124  1.790843  0.229875  0.397740  1.201343\n",
       "2083       8.504195  -1.378563  2.362360  2.122315  3.813338  1.492260\n",
       "2084       8.311902  -1.916312  0.251801 -0.553506 -1.146012 -1.740736\n",
       "2085       8.416877   0.482019  0.276718  0.199955  1.532236  1.047101"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCA = PCA.iloc[:, 1:7]\n",
    "PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge PCA dataframe with demographic and step data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important files below:\n",
    "\n",
    "1. no_band_PCA = PCA + Demographic + stepcount as continuous variables\n",
    "2. norm_no_band_PCA = PCA + Demographic + stepcount, Normalized as continuous variables\n",
    "3. band_PCA = PCA + Demographic + stepcount as discrete variables\n",
    "4. norm_band_PCA = PCA + Demographic + stepcount, Normalized as discrete variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_band_PCA = pd.concat([PCA, data1], axis = 1, join = 'outer')\n",
    "band_PCA = pd.concat([PCA, data2], axis = 1, join = 'outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "norm = MinMaxScaler()\n",
    "\n",
    "norm_no_band_PCA = pd.DataFrame(norm.fit_transform(no_band_PCA), index = no_band_PCA.index, columns = no_band_PCA.columns.values)\n",
    "norm_band_PCA = pd.DataFrame(norm.fit_transform(band_PCA), index = band_PCA.index, columns = band_PCA.columns.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Demographic: No Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.7333333333333333\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  122\n",
      "Training Accuracy: 0.6\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  200\n",
      "Training Accuracy: 0.7111111111111111\n",
      "Test Accuracy: 0.75\n",
      "Random State:  300\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.5\n",
      "Random State:  368\n",
      "Training Accuracy: 0.6888888888888889\n",
      "Test Accuracy: 0.5\n",
      "Random State:  400\n",
      "Training Accuracy: 0.6222222222222222\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  500\n",
      "Training Accuracy: 0.7555555555555555\n",
      "Test Accuracy: 0.75\n",
      "Random State:  600\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  700\n",
      "Training Accuracy: 0.7111111111111111\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  22\n",
      "Training Accuracy: 0.6888888888888889\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Mean Training Accuracy: 0.7088888888888889\n",
      "Mean Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "no_band_train_PCA = []\n",
    "no_band_test_PCA = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(no_band_PCA, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    no_band_train_PCA.append(svm_train_acc)\n",
    "    no_band_test_PCA.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(no_band_train_PCA)) \n",
    "print('Mean Test Accuracy:', mean(no_band_test_PCA)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Demographic: No Band,\n",
    "Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  122\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.75\n",
      "Random State:  200\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.75\n",
      "Random State:  300\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  368\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  400\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  500\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.5\n",
      "Random State:  600\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.9166666666666666\n",
      "Random State:  700\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.5\n",
      "Random State:  22\n",
      "Training Accuracy: 0.7333333333333333\n",
      "Test Accuracy: 0.75\n",
      "Mean Training Accuracy: 0.8044444444444444\n",
      "Mean Test Accuracy: 0.6833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "norm_no_band_train_PCA = []\n",
    "norm_no_band_test_PCA = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(norm_no_band_PCA, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    norm_no_band_train_PCA.append(svm_train_acc)\n",
    "    norm_no_band_test_PCA.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(norm_no_band_train_PCA)) \n",
    "print('Mean Test Accuracy:', mean(norm_no_band_test_PCA)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Demographic: Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.7333333333333333\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  122\n",
      "Training Accuracy: 0.6\n",
      "Test Accuracy: 0.8333333333333334\n",
      "Random State:  200\n",
      "Training Accuracy: 0.7111111111111111\n",
      "Test Accuracy: 0.75\n",
      "Random State:  300\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.5\n",
      "Random State:  368\n",
      "Training Accuracy: 0.6888888888888889\n",
      "Test Accuracy: 0.5\n",
      "Random State:  400\n",
      "Training Accuracy: 0.6222222222222222\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  500\n",
      "Training Accuracy: 0.7555555555555555\n",
      "Test Accuracy: 0.75\n",
      "Random State:  600\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  700\n",
      "Training Accuracy: 0.7111111111111111\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  22\n",
      "Training Accuracy: 0.6888888888888889\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Mean Training Accuracy: 0.7088888888888889\n",
      "Mean Test Accuracy: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "norm_no_band_train_PCA = []\n",
    "norm_no_band_test_PCA = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(no_band_PCA, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    norm_no_band_train_PCA.append(svm_train_acc)\n",
    "    norm_no_band_test_PCA.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(norm_no_band_train_PCA)) \n",
    "print('Mean Test Accuracy:', mean(norm_no_band_test_PCA)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA + Demographic: Band,\n",
    "Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State:  100\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  122\n",
      "Training Accuracy: 0.7777777777777778\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  200\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  300\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  368\n",
      "Training Accuracy: 0.8666666666666667\n",
      "Test Accuracy: 0.6666666666666666\n",
      "Random State:  400\n",
      "Training Accuracy: 0.8222222222222222\n",
      "Test Accuracy: 0.75\n",
      "Random State:  500\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.5\n",
      "Random State:  600\n",
      "Training Accuracy: 0.8\n",
      "Test Accuracy: 0.9166666666666666\n",
      "Random State:  700\n",
      "Training Accuracy: 0.8444444444444444\n",
      "Test Accuracy: 0.5833333333333334\n",
      "Random State:  22\n",
      "Training Accuracy: 0.7333333333333333\n",
      "Test Accuracy: 0.75\n",
      "Mean Training Accuracy: 0.8088888888888889\n",
      "Mean Test Accuracy: 0.6749999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "norm_band_train_PCA = []\n",
    "norm_band_test_PCA = []\n",
    "\n",
    "for i in random_state :\n",
    "    \n",
    "    train_df, test_df = train_test_split(norm_band_PCA, test_size=0.2, random_state= i)\n",
    "    \n",
    "    X_train = train_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_train = train_df['Weight_loss_band']  \n",
    "    \n",
    "    X_test  = test_df.drop('Weight_loss_band', axis=1)\n",
    "    Y_test = test_df['Weight_loss_band']  \n",
    "    \n",
    "    clf = svm.SVC(kernel = 'poly', gamma = 'scale')\n",
    "    clf.fit(X_train, Y_train)  \n",
    "\n",
    "    svm_train_acc = clf.score(X_train, Y_train)\n",
    "    svm_test_acc = clf.score(X_test, Y_test)\n",
    "    \n",
    "    norm_band_train_PCA.append(svm_train_acc)\n",
    "    norm_band_test_PCA.append(svm_test_acc)\n",
    "    \n",
    "    print('Random State: ', i)\n",
    "    \n",
    "    print('Training Accuracy:', svm_train_acc)\n",
    "    \n",
    "    print('Test Accuracy:', svm_test_acc)\n",
    "\n",
    "print('Mean Training Accuracy:', mean(norm_band_train_PCA)) \n",
    "print('Mean Test Accuracy:', mean(norm_band_test_PCA)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the model results dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = [d1_train_acc, d1_test_acc,\n",
    "                 d2_train_acc, d2_test_acc,\n",
    "                 data1_train_acc, data1_test_acc,\n",
    "                 data2_train_acc, data2_test_acc,\n",
    "                 no_band_train_acc, no_band_test_acc,\n",
    "                 norm_no_band_train_acc, norm_no_band_test_acc,\n",
    "                 band_train_acc, band_test_acc,\n",
    "                 norm_band_train_acc, norm_band_test_acc,\n",
    "                 no_band_train_PCA, no_band_test_PCA,\n",
    "                 norm_no_band_train_PCA, norm_no_band_test_PCA,\n",
    "                 band_train_PCA, band_test_PCA,\n",
    "                 norm_band_train_PCA, norm_band_test_PCA]\n",
    "\n",
    "\n",
    "results_train_mean = [mean(d1_train_acc), mean(d1_test_acc),\n",
    "                 mean(d2_train_acc), mean(d2_test_acc),\n",
    "                 mean(data1_train_acc), mean(data1_test_acc),\n",
    "                 mean(data2_train_acc), mean(data2_test_acc),\n",
    "                 mean(no_band_train_acc), mean(no_band_test_acc),\n",
    "                 mean(norm_no_band_train_acc), mean(norm_no_band_test_acc),\n",
    "                 mean(band_train_acc), mean(band_test_acc),\n",
    "                 mean(norm_band_train_acc), mean(norm_band_test_acc),\n",
    "                 mean(no_band_train_PCA), mean(no_band_test_PCA),\n",
    "                 mean(norm_no_band_train_PCA), mean(norm_no_band_test_PCA),\n",
    "                 mean(band_train_PCA), mean(band_test_PCA),\n",
    "                 mean(norm_band_train_PCA), mean(norm_band_test_PCA)]\n",
    "\n",
    "\n",
    "index = ['Dem: No Band', '* Dem: No Band',\n",
    "         'Dem: Band', '* Dem: Band', \n",
    "         'Dem + Step: No Band', '* Dem + Step: No Band',\n",
    "         'Dem + Step: Band', '* Dem + Step: Band',\n",
    "         'Dem + Step + KEGG: No Band', '* Dem + Step + KEGG: No Band',\n",
    "         'Dem + Step + KEGG: No Band, Normalized', '* Dem + Step + KEGG: No Band, Normalized',\n",
    "         'Dem + Step + KEGG: Band', '* Dem + Step + KEGG: Band',\n",
    "         'Dem + Step + KEGG: Band, Normalized', '* Dem + Step + KEGG: Band, Normalized',\n",
    "         'Dem + Step + PCA: No Band', '* Dem + Step + PCA: No Band',\n",
    "         'Dem + Step + PCA: No Band, Normalized', '* Dem + Step + PCA: No Band, Normalized',\n",
    "         'Dem + Step + PCA: Band', '* Dem + Step + PCA: Band',\n",
    "         'Dem + Step + PCA: Band, Normalized', '* Dem + Step + PCA: Band, Normalized', ]\n",
    "\n",
    "random_state = [100, 122, 200, 300, 368, 400, 500, 600, 700, 22]\n",
    "\n",
    "svm_table = pd.DataFrame(results_train, columns = random_state, index = index)\n",
    "svm_table['Average Model Performance'] = results_train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_table = svm_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm_table shows the results for all models, the code below selects the top from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 24)\n",
    "svm_table = svm_table.copy()\n",
    "result = svm_table.loc[:,['Dem: Band', '* Dem: Band',\n",
    "                'Dem + Step: Band', '* Dem + Step: Band', \n",
    "                 'Dem + Step + KEGG: No Band', '* Dem + Step + KEGG: No Band',\n",
    "                'Dem + Step + PCA: No Band, Normalized', '* Dem + Step + PCA: No Band, Normalized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dem: Band</th>\n",
       "      <th>* Dem: Band</th>\n",
       "      <th>Dem + Step: Band</th>\n",
       "      <th>* Dem + Step: Band</th>\n",
       "      <th>Dem + Step + KEGG: No Band</th>\n",
       "      <th>* Dem + Step + KEGG: No Band</th>\n",
       "      <th>Dem + Step + PCA: No Band, Normalized</th>\n",
       "      <th>* Dem + Step + PCA: No Band, Normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average Model Performance</th>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.815556</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dem: Band  * Dem: Band  Dem + Step: Band  \\\n",
       "100                         0.822222     0.666667          0.800000   \n",
       "122                         0.800000     0.750000          0.777778   \n",
       "200                         0.844444     0.583333          0.844444   \n",
       "300                         0.800000     0.666667          0.800000   \n",
       "368                         0.755556     0.833333          0.844444   \n",
       "400                         0.777778     0.666667          0.800000   \n",
       "500                         0.844444     0.500000          0.866667   \n",
       "600                         0.755556     0.833333          0.822222   \n",
       "700                         0.822222     0.583333          0.800000   \n",
       "22                          0.755556     0.750000          0.800000   \n",
       "Average Model Performance   0.797778     0.683333          0.815556   \n",
       "\n",
       "                           * Dem + Step: Band  Dem + Step + KEGG: No Band  \\\n",
       "100                                  0.750000                         1.0   \n",
       "122                                  0.750000                         1.0   \n",
       "200                                  0.583333                         1.0   \n",
       "300                                  0.750000                         1.0   \n",
       "368                                  0.500000                         1.0   \n",
       "400                                  0.833333                         1.0   \n",
       "500                                  0.583333                         1.0   \n",
       "600                                  0.750000                         1.0   \n",
       "700                                  0.583333                         1.0   \n",
       "22                                   0.916667                         1.0   \n",
       "Average Model Performance            0.700000                         1.0   \n",
       "\n",
       "                           * Dem + Step + KEGG: No Band  \\\n",
       "100                                            0.750000   \n",
       "122                                            0.916667   \n",
       "200                                            0.750000   \n",
       "300                                            0.750000   \n",
       "368                                            0.416667   \n",
       "400                                            0.750000   \n",
       "500                                            0.666667   \n",
       "600                                            0.583333   \n",
       "700                                            0.916667   \n",
       "22                                             0.750000   \n",
       "Average Model Performance                      0.725000   \n",
       "\n",
       "                           Dem + Step + PCA: No Band, Normalized  \\\n",
       "100                                                     0.777778   \n",
       "122                                                     0.777778   \n",
       "200                                                     0.844444   \n",
       "300                                                     0.844444   \n",
       "368                                                     0.822222   \n",
       "400                                                     0.822222   \n",
       "500                                                     0.822222   \n",
       "600                                                     0.777778   \n",
       "700                                                     0.822222   \n",
       "22                                                      0.733333   \n",
       "Average Model Performance                               0.804444   \n",
       "\n",
       "                           * Dem + Step + PCA: No Band, Normalized  \n",
       "100                                                       0.666667  \n",
       "122                                                       0.750000  \n",
       "200                                                       0.750000  \n",
       "300                                                       0.666667  \n",
       "368                                                       0.666667  \n",
       "400                                                       0.666667  \n",
       "500                                                       0.500000  \n",
       "600                                                       0.916667  \n",
       "700                                                       0.500000  \n",
       "22                                                        0.750000  \n",
       "Average Model Performance                                 0.683333  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_excel(\"svm_model_results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
